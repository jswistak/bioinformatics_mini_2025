{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Genomics Laboratory\n",
        "## Teacher's Solution Notebook\n",
        "\n",
        "This notebook contains fully solved exercises for the Genomics laboratory session. Each exercise demonstrates practical bioinformatics analysis using real biological data and APIs.\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Retrieve genomic data from public databases using REST APIs\n",
        "- Analyze DNA sequences and compute basic statistics\n",
        "- Work with genetic variants and their annotations\n",
        "- Integrate multi-omics data (genomics, epigenomics)\n",
        "- Design CRISPR guide RNAs\n",
        "- Model gene expression dynamics using ODEs\n",
        "\n",
        "---\n",
        "\n",
        "## Laboratory Pipeline Overview\n",
        "\n",
        "This laboratory session follows a complete bioinformatics analysis pipeline:\n",
        "\n",
        "1. **Exercise 1: Retrieve Gene Sequence**\n",
        "   - Fetch genomic sequence from Ensembl REST API\n",
        "   - Compute basic sequence statistics (GC content, CpG motifs, length)\n",
        "   - Visualize GC content along the sequence\n",
        "\n",
        "2. **Exercise 2: Fetch Variants**\n",
        "   - Retrieve known genetic variants (SNPs/INDELs) from Ensembl Variation API\n",
        "   - Plot variant distribution along the gene\n",
        "   - Annotate variant impact\n",
        "\n",
        "3. **Exercise 3: Fetch Methylation Data**\n",
        "   - Query ENCODE database for whole-genome bisulfite sequencing (WGBS) data\n",
        "   - Understand epigenomic datasets\n",
        "\n",
        "4. **Exercise 4: Merge Variant + Methylation Data**\n",
        "   - Integrate variant positions with methylation scores\n",
        "   - Identify regulatory SNPs (variants in high-methylation zones)\n",
        "\n",
        "5. **Exercise 5: CRISPR Guide Design**\n",
        "   - Identify PAM sites (NGG) for SpCas9\n",
        "   - Design and score guide RNAs using heuristics\n",
        "\n",
        "6. **Exercise 6: Synthetic Gene Circuit Simulation**\n",
        "   - Model gene expression using ordinary differential equations (ODEs)\n",
        "   - Simulate dynamic behavior of gene circuits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "%matplotlib inline\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from scipy.integrate import solve_ivp\n",
        "import os\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "# Set up output directory\n",
        "output_dir = \"lab_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Retrieve Gene Sequence Using an API\n",
        "\n",
        "**Goal:** Teach API usage, JSON parsing, and basic bioinformatics manipulation.\n",
        "\n",
        "**Background:** The Ensembl REST API provides programmatic access to genomic data including DNA sequences, gene annotations, and variant information. This exercise introduces you to working with REST APIs in bioinformatics.\n",
        "\n",
        "**Task:**\n",
        "1. Use Ensembl REST API to download the genomic sequence of a chosen gene (e.g., TP53, BRCA1, or TERT)\n",
        "2. Store the sequence as FASTA format\n",
        "3. Compute basic statistics:\n",
        "   - GC content (overall and using sliding window)\n",
        "   - Number of CpG motifs\n",
        "   - Sequence length\n",
        "4. Plot GC-content along the sequence using a sliding window\n",
        "\n",
        "**Key Concepts:**\n",
        "- REST API usage for biological databases\n",
        "- JSON parsing and data extraction\n",
        "- DNA sequence analysis\n",
        "- Sliding window operations\n",
        "- FASTA file format\n",
        "\n",
        "**Useful Ensembl Gene IDs:**\n",
        "- TP53: `ENSG00000141510`\n",
        "- BRCA1: `ENSG00000012048`\n",
        "- TERT: `ENSG00000164362`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement fetch_gene_sequence_ensembl function\n",
        "def fetch_gene_sequence_ensembl(gene_id):\n",
        "    \"\"\"\n",
        "    Fetch DNA sequence for a given human gene using Ensembl REST API.\n",
        "    \n",
        "    Parameters:\n",
        "    - gene_id (str): Ensembl gene ID (e.g., \"ENSG00000141510\" for TP53)\n",
        "    \n",
        "    Returns:\n",
        "    - str: Gene sequence in uppercase A/C/G/T\n",
        "    \"\"\"\n",
        "    url = f\"https://rest.ensembl.org/sequence/id/{gene_id}?content-type=application/json\"\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    if not response.ok:\n",
        "        raise Exception(f\"Failed to fetch sequence for {gene_id}\")\n",
        "    \n",
        "    data = response.json()\n",
        "    seq = data.get(\"seq\", \"\").upper()\n",
        "    \n",
        "    return seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Retrieve Gene Sequence\n",
        "print(\"=\" * 60)\n",
        "print(\"Exercise 1: Retrieve Gene Sequence Using Ensembl API\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Choose a gene to analyze\n",
        "# Options: TP53 (ENSG00000141510), BRCA1 (ENSG00000012048), TERT (ENSG00000164362)\n",
        "gene_id = \"ENSG00000141510\"  # TP53\n",
        "gene_name = \"TP53\"\n",
        "\n",
        "print(f\"\\nFetching sequence for {gene_name} ({gene_id})...\")\n",
        "\n",
        "try:\n",
        "    # Fetch the gene sequence using fetch_gene_sequence_ensembl\n",
        "    sequence = fetch_gene_sequence_ensembl(gene_id)\n",
        "    \n",
        "    print(f\"✓ Successfully retrieved sequence\")\n",
        "    print(f\"  Sequence length: {len(sequence):,} bp\")\n",
        "    print(f\"  First 50 bases: {sequence[:50]}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error fetching sequence: {e}\")\n",
        "    sequence = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store sequence as FASTA format\n",
        "if sequence is not None:\n",
        "    # Create FASTA format string\n",
        "    # FASTA format: first line starts with \">\", followed by description\n",
        "    # Subsequent lines contain the sequence (typically 60-80 characters per line)\n",
        "    fasta_header = f\">{gene_id} {gene_name}\"\n",
        "    \n",
        "    # Format sequence with line breaks (every 60 characters)\n",
        "    fasta_sequence = \"\\n\".join([sequence[i:i+60] for i in range(0, len(sequence), 60)])\n",
        "    fasta_content = f\"{fasta_header}\\n{fasta_sequence}\\n\"\n",
        "    \n",
        "    # Save to file\n",
        "    fasta_filename = f\"{output_dir}/{gene_name}_sequence.fasta\"\n",
        "    with open(fasta_filename, 'w') as f:\n",
        "        f.write(fasta_content)\n",
        "    \n",
        "    print(f\"✓ Sequence saved to {fasta_filename}\")\n",
        "    print(f\"\\nFASTA preview:\")\n",
        "    print(fasta_content[:200] + \"...\" if len(fasta_content) > 200 else fasta_content)\n",
        "else:\n",
        "    print(\"⚠ No sequence available to save\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute basic sequence statistics\n",
        "if sequence is not None:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Basic Sequence Statistics\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Calculate sequence length\n",
        "    seq_length = len(sequence)\n",
        "    \n",
        "    # Calculate overall GC content\n",
        "    # GC content = (G + C) / total_length\n",
        "    g_count = sequence.count(\"G\")\n",
        "    c_count = sequence.count(\"C\")\n",
        "    gc_count = g_count + c_count\n",
        "    gc_content = gc_count / seq_length if seq_length > 0 else 0\n",
        "    \n",
        "    # Count CpG motifs\n",
        "    # CpG motif = \"CG\" dinucleotide\n",
        "    cpg_count = sequence.count(\"CG\")\n",
        "    cpg_density = (cpg_count / seq_length) * 1000 if seq_length > 0 else 0\n",
        "    \n",
        "    # Count each nucleotide\n",
        "    a_count = sequence.count(\"A\")\n",
        "    t_count = sequence.count(\"T\")\n",
        "    \n",
        "    # Print statistics\n",
        "    print(f\"\\nSequence Statistics for {gene_name}:\")\n",
        "    print(f\"  Length: {seq_length:,} bp\")\n",
        "    print(f\"  GC content: {gc_content:.2%}\")\n",
        "    print(f\"  CpG motifs: {cpg_count:,}\")\n",
        "    print(f\"  CpG density: {cpg_density:.2f} per 1000 bp\")\n",
        "    print(f\"\\nNucleotide composition:\")\n",
        "    print(f\"  A: {a_count:,} ({a_count/seq_length:.2%})\")\n",
        "    print(f\"  T: {t_count:,} ({t_count/seq_length:.2%})\")\n",
        "    print(f\"  G: {g_count:,} ({g_count/seq_length:.2%})\")\n",
        "    print(f\"  C: {c_count:,} ({c_count/seq_length:.2%})\")\n",
        "else:\n",
        "    print(\"⚠ No sequence available for analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement compute_gc_content function\n",
        "def compute_gc_content(sequence, window=200):\n",
        "    \"\"\"\n",
        "    Compute GC-content using a sliding window across the sequence.\n",
        "    \n",
        "    Parameters:\n",
        "    - sequence (str): DNA sequence\n",
        "    - window (int): Window size for sliding window\n",
        "    \n",
        "    Returns:\n",
        "    - pandas.DataFrame: Columns ['start', 'end', 'gc_content']\n",
        "    \n",
        "    Algorithm:\n",
        "    1. Slide a window of size 'window' along the sequence\n",
        "    2. For each window, calculate GC content = (G + C) / window_size\n",
        "    3. Store start position, end position, and GC content\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    seq_len = len(sequence)\n",
        "    \n",
        "    # Implement sliding window\n",
        "    # Loop through sequence with step size = window\n",
        "    for i in range(0, seq_len - window + 1, window):\n",
        "        window_seq = sequence[i:i+window]\n",
        "        gc = (window_seq.count(\"G\") + window_seq.count(\"C\")) / window\n",
        "        results.append([i, i+window, gc])\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df_gc = pd.DataFrame(results, columns=['start', 'end', 'gc_content'])\n",
        "    \n",
        "    return df_gc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute GC content using sliding window\n",
        "if sequence is not None:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Computing GC Content with Sliding Window\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Set window size\n",
        "    window_size = 200  # 200 bp windows\n",
        "    \n",
        "    # Compute GC content using compute_gc_content function\n",
        "    df_gc = compute_gc_content(sequence, window=window_size)\n",
        "    \n",
        "    print(f\"✓ Computed GC content for {len(df_gc)} windows\")\n",
        "    print(f\"\\nFirst 5 windows:\")\n",
        "    print(df_gc.head())\n",
        "else:\n",
        "    print(\"⚠ No sequence available for GC content analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot GC content along the sequence\n",
        "if sequence is not None and 'df_gc' in locals() and df_gc is not None:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Visualizing GC Content Along Gene\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create plot\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Plot GC content\n",
        "    plt.plot(df_gc['start'], df_gc['gc_content'], linewidth=1.5, color='steelblue')\n",
        "    \n",
        "    # Add labels and title\n",
        "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"GC content\", fontsize=12, fontweight='bold')\n",
        "    plt.title(f\"GC Content Along {gene_name} Gene (window size: {window_size} bp)\", \n",
        "              fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Add horizontal line for overall GC content\n",
        "    plt.axhline(y=gc_content, color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Overall GC content: {gc_content:.2%}')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Add grid for better readability\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nGC Content Statistics:\")\n",
        "    print(f\"  Mean: {df_gc['gc_content'].mean():.3f}\")\n",
        "    print(f\"  Median: {df_gc['gc_content'].median():.3f}\")\n",
        "    print(f\"  Min: {df_gc['gc_content'].min():.3f}\")\n",
        "    print(f\"  Max: {df_gc['gc_content'].max():.3f}\")\n",
        "    print(f\"  Std Dev: {df_gc['gc_content'].std():.3f}\")\n",
        "else:\n",
        "    print(\"⚠ No GC content data available for plotting\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Fetch and Analyze Known Variants\n",
        "\n",
        "**Goal:** Introduce variant data, annotation, and visualization.\n",
        "\n",
        "**Background:** Genetic variants (SNPs, INDELs) are differences in DNA sequence between individuals. Understanding where variants occur and their functional impact is crucial for understanding disease mechanisms and personalized medicine. The Ensembl Variation API provides access to annotated variants from multiple sources.\n",
        "\n",
        "**Task:**\n",
        "1. Use Ensembl Variation API to fetch all SNPs for the gene\n",
        "2. Filter SNPs by:\n",
        "   - Location within promoter region (−1000 bp from gene start)\n",
        "   - Coding region\n",
        "   - High-impact variants (missense, nonsense)\n",
        "3. Plot:\n",
        "   - Histogram of variant density along the gene\n",
        "   - Scatter plot of variant impact score vs. genomic position\n",
        "\n",
        "**Key Concepts:**\n",
        "- Variant annotation and consequence types\n",
        "- Promoter regions and regulatory elements\n",
        "- Coding vs. non-coding variants\n",
        "- Variant impact classification\n",
        "- Data filtering and visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement fetch_variants_for_gene function\n",
        "def fetch_variants_for_gene(gene_id):\n",
        "    \"\"\"\n",
        "    Retrieve SNPs/INDELs for a given gene using Ensembl Variation API.\n",
        "    \n",
        "    Parameters:\n",
        "    - gene_id (str): Ensembl gene ID\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame: Variation table with columns:\n",
        "        ['id', 'start', 'end', 'alleles', 'consequence_type']\n",
        "    \"\"\"\n",
        "    url = f\"https://rest.ensembl.org/overlap/id/{gene_id}?feature=variation;content-type=application/json\"\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    if not response.ok:\n",
        "        raise Exception(f\"Failed to fetch variants for {gene_id}\")\n",
        "    \n",
        "    data = response.json()\n",
        "    \n",
        "    rows = []\n",
        "    for var in data:\n",
        "        rows.append([\n",
        "            var.get('id'),\n",
        "            var.get('start'),\n",
        "            var.get('end'),\n",
        "            var.get('alleles'),\n",
        "            var.get('consequence_type')\n",
        "        ])\n",
        "    \n",
        "    return pd.DataFrame(rows, columns=['id', 'start', 'end', 'alleles', 'consequence_type'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2: Fetch and Analyze Known Variants\n",
        "print(\"=\" * 60)\n",
        "print(\"Exercise 2: Fetch and Analyze Known Variants\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if we have the gene sequence from Exercise 1\n",
        "if 'sequence' not in locals() or sequence is None:\n",
        "    print(\"⚠ Warning: Gene sequence not found. Please run Exercise 1 first.\")\n",
        "    # Re-fetch if needed\n",
        "    if 'gene_id' in locals():\n",
        "        sequence = fetch_gene_sequence_ensembl(gene_id)\n",
        "        print(f\"✓ Fetched sequence for variant analysis\")\n",
        "    else:\n",
        "        print(\"✗ Cannot proceed without gene information\")\n",
        "        df_variants = None\n",
        "else:\n",
        "    # Get gene start position (we'll use position 0 as reference, or fetch gene info)\n",
        "    # For simplicity, we'll use the sequence start as gene start\n",
        "    # In practice, you'd fetch gene coordinates from Ensembl\n",
        "    gene_start = 0  # Relative to sequence start\n",
        "    \n",
        "    print(f\"\\nFetching variants for {gene_name} ({gene_id})...\")\n",
        "    \n",
        "    try:\n",
        "        # Fetch variants using Ensembl Variation API\n",
        "        df_variants = fetch_variants_for_gene(gene_id)\n",
        "        \n",
        "        print(f\"✓ Retrieved {len(df_variants)} variants\")\n",
        "        \n",
        "        if len(df_variants) > 0:\n",
        "            # Convert start/end to numeric if needed\n",
        "            df_variants['start'] = pd.to_numeric(df_variants['start'], errors='coerce')\n",
        "            df_variants['end'] = pd.to_numeric(df_variants['end'], errors='coerce')\n",
        "            \n",
        "            # Remove rows with invalid positions\n",
        "            df_variants = df_variants.dropna(subset=['start', 'end'])\n",
        "            \n",
        "            print(f\"  Valid variants: {len(df_variants)}\")\n",
        "            print(f\"\\nFirst 5 variants:\")\n",
        "            print(df_variants.head())\n",
        "            \n",
        "            # Display variant statistics\n",
        "            print(f\"\\nVariant Statistics:\")\n",
        "            print(f\"  Total variants: {len(df_variants)}\")\n",
        "            if 'consequence_type' in df_variants.columns:\n",
        "                print(f\"\\nConsequence types:\")\n",
        "                consequence_counts = df_variants['consequence_type'].value_counts()\n",
        "                for cons, count in consequence_counts.head(10).items():\n",
        "                    print(f\"    {cons}: {count}\")\n",
        "        else:\n",
        "            print(\"⚠ No variants found for this gene\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error fetching variants: {e}\")\n",
        "        df_variants = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter variants by location and impact\n",
        "if df_variants is not None and len(df_variants) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Filtering Variants\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Get sequence length for reference\n",
        "    seq_length = len(sequence) if 'sequence' in locals() else 0\n",
        "    \n",
        "    # Filter 1: Promoter region (-1000 bp from gene start)\n",
        "    # Note: We'll use the minimum start position as gene start reference\n",
        "    min_start = df_variants['start'].min()\n",
        "    promoter_start = min_start - 1000\n",
        "    promoter_end = min_start\n",
        "    \n",
        "    df_promoter = df_variants[\n",
        "        (df_variants['start'] >= promoter_start) & \n",
        "        (df_variants['start'] <= promoter_end)\n",
        "    ].copy()\n",
        "    \n",
        "    print(f\"\\n1. Promoter region variants (-1000 bp from gene start):\")\n",
        "    print(f\"   Found {len(df_promoter)} variants in promoter region\")\n",
        "    if len(df_promoter) > 0:\n",
        "        print(f\"   Position range: {df_promoter['start'].min():,} - {df_promoter['start'].max():,} bp\")\n",
        "    \n",
        "    # Filter 2: Coding region variants\n",
        "    # High-impact variants typically affect coding sequences\n",
        "    # We'll identify variants with coding-related consequences\n",
        "    coding_consequences = [\n",
        "        'missense_variant', 'nonsense_variant', 'synonymous_variant',\n",
        "        'stop_gained', 'stop_lost', 'start_lost', 'frameshift_variant',\n",
        "        'inframe_insertion', 'inframe_deletion', 'protein_altering_variant'\n",
        "    ]\n",
        "    \n",
        "    df_coding = df_variants[\n",
        "        df_variants['consequence_type'].isin(coding_consequences)\n",
        "    ].copy()\n",
        "    \n",
        "    print(f\"\\n2. Coding region variants:\")\n",
        "    print(f\"   Found {len(df_coding)} variants in coding regions\")\n",
        "    if len(df_coding) > 0:\n",
        "        print(f\"   Position range: {df_coding['start'].min():,} - {df_coding['start'].max():,} bp\")\n",
        "    \n",
        "    # Filter 3: High-impact variants (missense, nonsense)\n",
        "    high_impact_consequences = [\n",
        "        'missense_variant', 'nonsense_variant', 'stop_gained', \n",
        "        'stop_lost', 'start_lost', 'frameshift_variant'\n",
        "    ]\n",
        "    \n",
        "    df_high_impact = df_variants[\n",
        "        df_variants['consequence_type'].isin(high_impact_consequences)\n",
        "    ].copy()\n",
        "    \n",
        "    print(f\"\\n3. High-impact variants (missense, nonsense, etc.):\")\n",
        "    print(f\"   Found {len(df_high_impact)} high-impact variants\")\n",
        "    if len(df_high_impact) > 0:\n",
        "        print(f\"   Position range: {df_high_impact['start'].min():,} - {df_high_impact['start'].max():,} bp\")\n",
        "        print(f\"\\n   Breakdown by consequence type:\")\n",
        "        impact_counts = df_high_impact['consequence_type'].value_counts()\n",
        "        for cons, count in impact_counts.items():\n",
        "            print(f\"     {cons}: {count}\")\n",
        "    \n",
        "    print(f\"\\n✓ Filtering complete\")\n",
        "else:\n",
        "    print(\"⚠ No variants available for filtering\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assign impact scores to variants\n",
        "if df_variants is not None and len(df_variants) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Assigning Impact Scores\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Define impact score mapping\n",
        "    # Higher score = more severe impact\n",
        "    impact_scores = {\n",
        "        'transcript_ablation': 10,\n",
        "        'splice_acceptor_variant': 9,\n",
        "        'splice_donor_variant': 9,\n",
        "        'stop_gained': 8,\n",
        "        'frameshift_variant': 8,\n",
        "        'stop_lost': 8,\n",
        "        'start_lost': 8,\n",
        "        'nonsense_variant': 7,\n",
        "        'missense_variant': 6,\n",
        "        'inframe_insertion': 5,\n",
        "        'inframe_deletion': 5,\n",
        "        'protein_altering_variant': 5,\n",
        "        'synonymous_variant': 2,\n",
        "        'stop_retained_variant': 2,\n",
        "        'coding_sequence_variant': 3,\n",
        "        'mature_miRNA_variant': 4,\n",
        "        '5_prime_UTR_variant': 2,\n",
        "        '3_prime_UTR_variant': 2,\n",
        "        'intron_variant': 1,\n",
        "        'intergenic_variant': 0,\n",
        "        'upstream_gene_variant': 1,\n",
        "        'downstream_gene_variant': 1,\n",
        "        'regulatory_region_variant': 2,\n",
        "    }\n",
        "    \n",
        "    # Assign impact scores\n",
        "    df_variants['impact_score'] = df_variants['consequence_type'].map(\n",
        "        lambda x: impact_scores.get(x, 1) if pd.notna(x) else 1\n",
        "    )\n",
        "    \n",
        "    print(f\"✓ Assigned impact scores to {len(df_variants)} variants\")\n",
        "    print(f\"\\nImpact score distribution:\")\n",
        "    score_counts = df_variants['impact_score'].value_counts().sort_index(ascending=False)\n",
        "    for score, count in score_counts.items():\n",
        "        print(f\"  Score {score}: {count} variants\")\n",
        "    \n",
        "    print(f\"\\nMean impact score: {df_variants['impact_score'].mean():.2f}\")\n",
        "    print(f\"Max impact score: {df_variants['impact_score'].max()}\")\n",
        "    print(f\"Min impact score: {df_variants['impact_score'].min()}\")\n",
        "else:\n",
        "    print(\"⚠ No variants available for impact scoring\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 1: Histogram of variant density along the gene\n",
        "if df_variants is not None and len(df_variants) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Plot 1: Variant Density Histogram\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Create histogram\n",
        "    bins = 50\n",
        "    plt.hist(df_variants['start'], bins=bins, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    \n",
        "    # Add vertical lines for filtered regions if available\n",
        "    if 'df_promoter' in locals() and len(df_promoter) > 0:\n",
        "        plt.axvspan(promoter_start, promoter_end, alpha=0.2, color='orange', \n",
        "                    label='Promoter region (-1000 bp)')\n",
        "    \n",
        "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Variant count\", fontsize=12, fontweight='bold')\n",
        "    plt.title(f\"Variant Density Along {gene_name} Gene\", fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    if 'df_promoter' in locals() and len(df_promoter) > 0:\n",
        "        plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✓ Histogram created with {bins} bins\")\n",
        "    print(f\"  Total variants plotted: {len(df_variants)}\")\n",
        "else:\n",
        "    print(\"⚠ No variants available for density plot\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 2: Scatter plot of variant impact score vs. genomic position\n",
        "if df_variants is not None and len(df_variants) > 0 and 'impact_score' in df_variants.columns:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Plot 2: Variant Impact Score vs. Genomic Position\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    plt.figure(figsize=(14, 6))\n",
        "    \n",
        "    # Create scatter plot\n",
        "    # Color code by impact score\n",
        "    scatter = plt.scatter(df_variants['start'], df_variants['impact_score'], \n",
        "                         c=df_variants['impact_score'], cmap='RdYlGn_r',\n",
        "                         s=30, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "    \n",
        "    # Highlight high-impact variants\n",
        "    # Update df_high_impact to include impact_score if it doesn't have it\n",
        "    if 'df_high_impact' in locals() and len(df_high_impact) > 0:\n",
        "        # If df_high_impact doesn't have impact_score, merge it from df_variants\n",
        "        if 'impact_score' not in df_high_impact.columns:\n",
        "            # Try to merge on 'id' first, if that fails, merge on 'start'\n",
        "            try:\n",
        "                df_high_impact = df_high_impact.merge(\n",
        "                    df_variants[['id', 'impact_score']], \n",
        "                    on='id', \n",
        "                    how='left'\n",
        "                )\n",
        "            except:\n",
        "                # If merge on 'id' fails, try merging on 'start'\n",
        "                try:\n",
        "                    df_high_impact = df_high_impact.merge(\n",
        "                        df_variants[['start', 'impact_score']], \n",
        "                        on='start', \n",
        "                        how='left'\n",
        "                    )\n",
        "                except:\n",
        "                    # If both fail, get impact_score by matching start positions\n",
        "                    df_high_impact['impact_score'] = df_high_impact['start'].map(\n",
        "                        dict(zip(df_variants['start'], df_variants['impact_score']))\n",
        "                    )\n",
        "        # Only plot if impact_score column exists and has valid values\n",
        "        if 'impact_score' in df_high_impact.columns and df_high_impact['impact_score'].notna().any():\n",
        "            plt.scatter(df_high_impact['start'], df_high_impact['impact_score'],\n",
        "                       s=100, alpha=0.8, color='red', edgecolors='darkred', \n",
        "                       linewidths=1.5, marker='*', label='High-impact variants',\n",
        "                       zorder=5)\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Impact Score', fontsize=11, fontweight='bold')\n",
        "    \n",
        "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Impact Score\", fontsize=12, fontweight='bold')\n",
        "    plt.title(f\"Variant Impact Score vs. Genomic Position for {gene_name}\", \n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    if 'df_high_impact' in locals() and len(df_high_impact) > 0:\n",
        "        plt.legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✓ Scatter plot created\")\n",
        "    print(f\"  Total variants plotted: {len(df_variants)}\")\n",
        "    if 'df_high_impact' in locals() and len(df_high_impact) > 0:\n",
        "        print(f\"  High-impact variants highlighted: {len(df_high_impact)}\")\n",
        "    \n",
        "    # Additional analysis: correlation between position and impact\n",
        "    correlation = df_variants['start'].corr(df_variants['impact_score'])\n",
        "    print(f\"\\nCorrelation between position and impact score: {correlation:.3f}\")\n",
        "else:\n",
        "    print(\"⚠ No variants available for impact score plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Retrieve Methylation Profile (ENCODE API)\n",
        "\n",
        "**Goal:** Integrate multi-omics data to identify regulatory variants.\n",
        "\n",
        "**Background:** DNA methylation is an epigenetic modification that can regulate gene expression. Whole-genome bisulfite sequencing (WGBS) provides genome-wide methylation profiles. Integrating variant data with methylation data helps identify regulatory SNPs (rSNPs) that may affect gene expression through epigenetic mechanisms.\n",
        "\n",
        "**Task:**\n",
        "1. Query ENCODE REST API for DNA-methylation tracks (WGBS) for the gene region\n",
        "2. Download methylation beta values\n",
        "3. Merge SNP positions (from Exercise 2) with methylation scores\n",
        "4. Identify candidate \"regulatory SNPs\":\n",
        "   - SNPs falling in highly methylated CpG islands\n",
        "   - Variants inside promoters with methylation > 0.7\n",
        "\n",
        "**Key Concepts:**\n",
        "- Epigenomics and DNA methylation\n",
        "- Multi-omics data integration\n",
        "- Regulatory SNPs (rSNPs)\n",
        "- CpG islands and promoter methylation\n",
        "- ENCODE database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement fetch_encode_methylation function\n",
        "def fetch_encode_methylation(gene_name, limit=200):\n",
        "    \"\"\"\n",
        "    Retrieve WGBS methylation track files from ENCODE.\n",
        "    \n",
        "    Parameters:\n",
        "    - gene_name (str): Used only for reference; ENCODE query is global\n",
        "    - limit (int): Max returned records\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame: Minimal metadata table for methylation files\n",
        "    \"\"\"\n",
        "    url = \"https://www.encodeproject.org/search/\"\n",
        "    params = {\n",
        "        \"type\": \"File\",\n",
        "        \"assay_title\": \"WGBS\",\n",
        "        \"status\": \"released\",\n",
        "        \"limit\": limit,\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "    \n",
        "    response = requests.get(url, params=params, headers={\"accept\": \"application/json\"})\n",
        "    if not response.ok:\n",
        "        raise Exception(\"Failed to query ENCODE.\")\n",
        "    \n",
        "    data = response.json()\n",
        "    \n",
        "    rows = []\n",
        "    for hit in data.get('@graph', []):\n",
        "        rows.append([\n",
        "            hit.get('accession'),\n",
        "            hit.get('file_format'),\n",
        "            hit.get('output_type'),\n",
        "            hit.get('href')\n",
        "        ])\n",
        "    \n",
        "    return pd.DataFrame(rows, columns=['accession', 'format', 'output_type', 'url'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3: Retrieve Methylation Profile\n",
        "print(\"=\" * 60)\n",
        "print(\"Exercise 3: Retrieve Methylation Profile (ENCODE API)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if we have variants from Exercise 2\n",
        "if 'df_variants' not in locals() or df_variants is None:\n",
        "    print(\"⚠ Warning: Variants not found. Please run Exercise 2 first.\")\n",
        "    df_variants = None\n",
        "\n",
        "if 'gene_name' not in locals():\n",
        "    gene_name = \"TP53\"\n",
        "\n",
        "print(f\"\\nQuerying ENCODE for WGBS methylation data...\")\n",
        "\n",
        "try:\n",
        "    # Query ENCODE API for WGBS files\n",
        "    df_methylation_files = fetch_encode_methylation(gene_name, limit=50)\n",
        "    \n",
        "    print(f\"✓ Retrieved metadata for {len(df_methylation_files)} WGBS files\")\n",
        "    print(f\"\\nFirst 5 files:\")\n",
        "    print(df_methylation_files.head())\n",
        "    \n",
        "    print(f\"\\nFile formats:\")\n",
        "    print(df_methylation_files['format'].value_counts())\n",
        "    \n",
        "    print(f\"\\nOutput types:\")\n",
        "    print(df_methylation_files['output_type'].value_counts())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"✗ Error querying ENCODE: {e}\")\n",
        "    df_methylation_files = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate methylation beta values for the gene region\n",
        "# Note: In practice, you would download and parse large WGBS files\n",
        "# For this exercise, we'll simulate methylation values based on CpG positions\n",
        "\n",
        "if 'sequence' in locals() and sequence is not None and df_variants is not None and len(df_variants) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Generating Methylation Profile\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Find all CpG positions in the sequence\n",
        "    cpg_positions = []\n",
        "    for i in range(len(sequence) - 1):\n",
        "        if sequence[i:i+2] == \"CG\":\n",
        "            cpg_positions.append(i)\n",
        "    \n",
        "    print(f\"✓ Found {len(cpg_positions)} CpG sites in sequence\")\n",
        "    \n",
        "    # Create methylation profile\n",
        "    # Simulate methylation beta values (0-1 scale) with some structure:\n",
        "    # - Higher methylation in CpG islands\n",
        "    # - Lower methylation in gene body\n",
        "    # - Variable methylation in promoter\n",
        "    \n",
        "    # Get variant positions for reference\n",
        "    variant_positions = df_variants['start'].values\n",
        "    \n",
        "    # Create methylation DataFrame\n",
        "    # For each variant position, find nearest CpG and assign methylation\n",
        "    methylation_data = []\n",
        "    \n",
        "    for pos in variant_positions:\n",
        "        # Find nearest CpG site\n",
        "        if len(cpg_positions) > 0:\n",
        "            nearest_cpg_idx = np.argmin(np.abs(np.array(cpg_positions) - pos))\n",
        "            nearest_cpg_pos = cpg_positions[nearest_cpg_idx]\n",
        "            distance_to_cpg = abs(pos - nearest_cpg_pos)\n",
        "            \n",
        "            # Simulate methylation: higher near CpG sites, lower far away\n",
        "            # Also consider if in promoter region\n",
        "            if 'df_promoter' in locals() and len(df_promoter) > 0:\n",
        "                in_promoter = (pos >= promoter_start) and (pos <= promoter_end)\n",
        "            else:\n",
        "                in_promoter = False\n",
        "            \n",
        "            # Base methylation: higher in promoter, lower in gene body\n",
        "            if in_promoter:\n",
        "                base_methylation = 0.6 + np.random.rand() * 0.3  # 0.6-0.9\n",
        "            else:\n",
        "                base_methylation = 0.3 + np.random.rand() * 0.4  # 0.3-0.7\n",
        "            \n",
        "            # Adjust based on distance to CpG\n",
        "            if distance_to_cpg < 100:\n",
        "                methylation = base_methylation + (100 - distance_to_cpg) / 100 * 0.2\n",
        "                methylation = min(1.0, methylation)\n",
        "            else:\n",
        "                methylation = base_methylation - min(0.2, distance_to_cpg / 1000)\n",
        "                methylation = max(0.0, methylation)\n",
        "            \n",
        "            methylation_data.append({\n",
        "                'position': pos,\n",
        "                'nearest_cpg': nearest_cpg_pos,\n",
        "                'distance_to_cpg': distance_to_cpg,\n",
        "                'methylation': methylation\n",
        "            })\n",
        "        else:\n",
        "            # No CpG sites found, assign random methylation\n",
        "            methylation_data.append({\n",
        "                'position': pos,\n",
        "                'nearest_cpg': None,\n",
        "                'distance_to_cpg': None,\n",
        "                'methylation': np.random.rand()\n",
        "            })\n",
        "    \n",
        "    df_methylation = pd.DataFrame(methylation_data)\n",
        "    \n",
        "    print(f\"✓ Generated methylation profile for {len(df_methylation)} variant positions\")\n",
        "    print(f\"\\nMethylation statistics:\")\n",
        "    print(f\"  Mean: {df_methylation['methylation'].mean():.3f}\")\n",
        "    print(f\"  Median: {df_methylation['methylation'].median():.3f}\")\n",
        "    print(f\"  Min: {df_methylation['methylation'].min():.3f}\")\n",
        "    print(f\"  Max: {df_methylation['methylation'].max():.3f}\")\n",
        "    print(f\"  Std Dev: {df_methylation['methylation'].std():.3f}\")\n",
        "    \n",
        "    # Identify CpG islands (regions with high CpG density)\n",
        "    # Simple definition: regions with CpG density > 0.6\n",
        "    if len(cpg_positions) > 0:\n",
        "        cpg_islands = []\n",
        "        window_size = 200\n",
        "        for i in range(0, len(sequence) - window_size, window_size // 2):\n",
        "            window_cpgs = [cp for cp in cpg_positions if i <= cp < i + window_size]\n",
        "            cpg_density = len(window_cpgs) / window_size\n",
        "            if cpg_density > 0.6:\n",
        "                cpg_islands.append((i, i + window_size, cpg_density))\n",
        "        \n",
        "        print(f\"\\n✓ Identified {len(cpg_islands)} CpG islands (density > 0.6)\")\n",
        "        if len(cpg_islands) > 0:\n",
        "            print(f\"  CpG island positions:\")\n",
        "            for start, end, density in cpg_islands[:5]:  # Show first 5\n",
        "                print(f\"    {start:,} - {end:,} bp (density: {density:.3f})\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ Sequence or variants not available for methylation profile generation\")\n",
        "    df_methylation = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge variants with methylation scores\n",
        "if df_variants is not None and len(df_variants) > 0 and df_methylation is not None and len(df_methylation) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Merging Variants with Methylation Data\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Merge on position\n",
        "    df_merged = df_variants.merge(\n",
        "        df_methylation[['position', 'methylation', 'nearest_cpg', 'distance_to_cpg']],\n",
        "        left_on='start',\n",
        "        right_on='position',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Fill missing methylation values with median\n",
        "    if df_merged['methylation'].isna().any():\n",
        "        median_methylation = df_merged['methylation'].median()\n",
        "        df_merged['methylation'] = df_merged['methylation'].fillna(median_methylation)\n",
        "        print(f\"  Filled {df_merged['methylation'].isna().sum()} missing values with median\")\n",
        "    \n",
        "    print(f\"✓ Merged {len(df_merged)} variants with methylation data\")\n",
        "    print(f\"\\nMerged data preview:\")\n",
        "    print(df_merged[['id', 'start', 'consequence_type', 'impact_score', 'methylation']].head(10))\n",
        "    \n",
        "    print(f\"\\nMethylation distribution in merged data:\")\n",
        "    print(f\"  Mean: {df_merged['methylation'].mean():.3f}\")\n",
        "    print(f\"  Median: {df_merged['methylation'].median():.3f}\")\n",
        "    print(f\"  Variants with methylation > 0.7: {(df_merged['methylation'] > 0.7).sum()}\")\n",
        "    print(f\"  Variants with methylation > 0.8: {(df_merged['methylation'] > 0.8).sum()}\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ Cannot merge: variants or methylation data not available\")\n",
        "    df_merged = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify candidate regulatory SNPs\n",
        "if df_merged is not None and len(df_merged) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Identifying Candidate Regulatory SNPs\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Criterion 1: SNPs in highly methylated CpG islands\n",
        "    # Define CpG islands as regions with CpG density > 0.6\n",
        "    # and methylation > 0.7\n",
        "    if 'cpg_islands' in locals() and len(cpg_islands) > 0:\n",
        "        regulatory_snps_cpg = []\n",
        "        for _, row in df_merged.iterrows():\n",
        "            pos = row['start']\n",
        "            methylation = row['methylation']\n",
        "            # Check if variant is in a CpG island\n",
        "            in_cpg_island = any(start <= pos < end for start, end, _ in cpg_islands)\n",
        "            if in_cpg_island and methylation > 0.7:\n",
        "                regulatory_snps_cpg.append(row)\n",
        "        \n",
        "        df_regulatory_cpg = pd.DataFrame(regulatory_snps_cpg) if regulatory_snps_cpg else pd.DataFrame()\n",
        "        \n",
        "        print(f\"\\n1. Regulatory SNPs in highly methylated CpG islands:\")\n",
        "        print(f\"   Found {len(df_regulatory_cpg)} candidate regulatory SNPs\")\n",
        "        if len(df_regulatory_cpg) > 0:\n",
        "            print(f\"   Criteria: In CpG island AND methylation > 0.7\")\n",
        "            print(f\"\\n   Top candidates:\")\n",
        "            display_cols = ['id', 'start', 'consequence_type', 'impact_score', 'methylation']\n",
        "            print(df_regulatory_cpg[display_cols].head(10))\n",
        "    else:\n",
        "        print(f\"\\n1. Regulatory SNPs in highly methylated CpG islands:\")\n",
        "        print(f\"   No CpG islands identified or methylation data not available\")\n",
        "        df_regulatory_cpg = pd.DataFrame()\n",
        "    \n",
        "    # Criterion 2: Variants in promoters with methylation > 0.7\n",
        "    if 'df_promoter' in locals() and len(df_promoter) > 0:\n",
        "        # Get promoter variants with methylation data\n",
        "        promoter_variants = df_merged[df_merged['start'].isin(df_promoter['start'])]\n",
        "        df_regulatory_promoter = promoter_variants[promoter_variants['methylation'] > 0.7].copy()\n",
        "        \n",
        "        print(f\"\\n2. Regulatory SNPs in promoters with methylation > 0.7:\")\n",
        "        print(f\"   Found {len(df_regulatory_promoter)} candidate regulatory SNPs\")\n",
        "        if len(df_regulatory_promoter) > 0:\n",
        "            print(f\"   Criteria: In promoter region AND methylation > 0.7\")\n",
        "            print(f\"\\n   Top candidates:\")\n",
        "            display_cols = ['id', 'start', 'consequence_type', 'impact_score', 'methylation']\n",
        "            print(df_regulatory_promoter[display_cols].head(10))\n",
        "    else:\n",
        "        print(f\"\\n2. Regulatory SNPs in promoters with methylation > 0.7:\")\n",
        "        print(f\"   No promoter variants identified\")\n",
        "        df_regulatory_promoter = pd.DataFrame()\n",
        "    \n",
        "    # Combine all regulatory SNPs\n",
        "    if len(df_regulatory_cpg) > 0 or len(df_regulatory_promoter) > 0:\n",
        "        # Combine and remove duplicates\n",
        "        all_regulatory = pd.concat([df_regulatory_cpg, df_regulatory_promoter], ignore_index=True)\n",
        "        df_regulatory_all = all_regulatory.drop_duplicates(subset=['id'], keep='first')\n",
        "        \n",
        "        print(f\"\\n\" + \"=\" * 60)\n",
        "        print(f\"Summary: Total Unique Regulatory SNPs\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"  Total candidate regulatory SNPs: {len(df_regulatory_all)}\")\n",
        "        print(f\"  From CpG islands: {len(df_regulatory_cpg)}\")\n",
        "        print(f\"  From promoters: {len(df_regulatory_promoter)}\")\n",
        "        print(f\"  Unique (after deduplication): {len(df_regulatory_all)}\")\n",
        "        \n",
        "        if len(df_regulatory_all) > 0:\n",
        "            print(f\"\\n  Regulatory SNP characteristics:\")\n",
        "            print(f\"    Mean methylation: {df_regulatory_all['methylation'].mean():.3f}\")\n",
        "            print(f\"    Mean impact score: {df_regulatory_all['impact_score'].mean():.2f}\")\n",
        "            print(f\"\\n  Consequence types:\")\n",
        "            cons_counts = df_regulatory_all['consequence_type'].value_counts()\n",
        "            for cons, count in cons_counts.head(5).items():\n",
        "                print(f\"    {cons}: {count}\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ No regulatory SNPs identified based on the criteria\")\n",
        "        df_regulatory_all = pd.DataFrame()\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ Cannot identify regulatory SNPs: merged data not available\")\n",
        "    df_regulatory_all = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize methylation profile and regulatory SNPs\n",
        "if df_merged is not None and len(df_merged) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Visualizing Methylation Profile and Regulatory SNPs\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "    \n",
        "    # Plot 1: Methylation along gene with variant positions\n",
        "    ax1 = axes[0]\n",
        "    \n",
        "    # Plot all variants colored by methylation\n",
        "    scatter1 = ax1.scatter(df_merged['start'], df_merged['methylation'],\n",
        "                          c=df_merged['methylation'], cmap='RdYlBu',\n",
        "                          s=50, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "    \n",
        "    # Highlight regulatory SNPs\n",
        "    if 'df_regulatory_all' in locals() and len(df_regulatory_all) > 0:\n",
        "        ax1.scatter(df_regulatory_all['start'], df_regulatory_all['methylation'],\n",
        "                   s=150, alpha=0.9, color='red', edgecolors='darkred',\n",
        "                   linewidths=2, marker='*', label='Regulatory SNPs', zorder=5)\n",
        "    \n",
        "    # Add promoter region highlight\n",
        "    if 'df_promoter' in locals() and len(df_promoter) > 0:\n",
        "        ax1.axvspan(promoter_start, promoter_end, alpha=0.2, color='orange',\n",
        "                   label='Promoter region')\n",
        "    \n",
        "    # Add CpG island highlights\n",
        "    if 'cpg_islands' in locals() and len(cpg_islands) > 0:\n",
        "        for start, end, density in cpg_islands:\n",
        "            ax1.axvspan(start, end, alpha=0.15, color='green')\n",
        "    \n",
        "    cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
        "    cbar1.set_label('Methylation (beta value)', fontsize=11, fontweight='bold')\n",
        "    \n",
        "    ax1.set_xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
        "    ax1.set_ylabel(\"Methylation (beta value)\", fontsize=12, fontweight='bold')\n",
        "    ax1.set_title(f\"Methylation Profile and Regulatory SNPs for {gene_name}\", \n",
        "                  fontsize=14, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(loc='upper right')\n",
        "    \n",
        "    # Plot 2: Methylation vs Impact Score\n",
        "    ax2 = axes[1]\n",
        "    \n",
        "    scatter2 = ax2.scatter(df_merged['impact_score'], df_merged['methylation'],\n",
        "                          c=df_merged['start'], cmap='viridis',\n",
        "                          s=50, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "    \n",
        "    # Highlight regulatory SNPs\n",
        "    if 'df_regulatory_all' in locals() and len(df_regulatory_all) > 0:\n",
        "        ax2.scatter(df_regulatory_all['impact_score'], df_regulatory_all['methylation'],\n",
        "                   s=150, alpha=0.9, color='red', edgecolors='darkred',\n",
        "                   linewidths=2, marker='*', label='Regulatory SNPs', zorder=5)\n",
        "    \n",
        "    # Add threshold lines\n",
        "    ax2.axhline(y=0.7, color='orange', linestyle='--', linewidth=2,\n",
        "               label='Methylation threshold (0.7)')\n",
        "    \n",
        "    cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
        "    cbar2.set_label('Genomic position (bp)', fontsize=11, fontweight='bold')\n",
        "    \n",
        "    ax2.set_xlabel(\"Variant Impact Score\", fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel(\"Methylation (beta value)\", fontsize=12, fontweight='bold')\n",
        "    ax2.set_title(\"Methylation vs. Variant Impact Score\", fontsize=14, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✓ Visualization complete\")\n",
        "    print(f\"  Total variants plotted: {len(df_merged)}\")\n",
        "    if 'df_regulatory_all' in locals() and len(df_regulatory_all) > 0:\n",
        "        print(f\"  Regulatory SNPs highlighted: {len(df_regulatory_all)}\")\n",
        "else:\n",
        "    print(\"⚠ No data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Design CRISPR Guide RNAs\n",
        "\n",
        "**Goal:** Connect sequence data with computational CRISPR design.\n",
        "\n",
        "**Background:** CRISPR-Cas9 is a genome editing technology that uses a guide RNA (gRNA) to direct the Cas9 nuclease to specific DNA sequences. The SpCas9 system requires a Protospacer Adjacent Motif (PAM) sequence \"NGG\" (where N is any nucleotide) immediately downstream of the target site. Effective guide design requires considering multiple factors including GC content, avoiding repetitive sequences, and minimizing off-target effects.\n",
        "\n",
        "**Task:**\n",
        "1. Using the gene sequence from Exercise 1:\n",
        "   - Identify all NGG PAM sites (for SpCas9)\n",
        "   - Extract candidate 20-bp guide sequences\n",
        "2. Score each guide using:\n",
        "   - GC content (optimal ~50%)\n",
        "   - Avoiding poly-T runs\n",
        "   - Position relative to transcription start site\n",
        "3. Use CRISPOR API or Benchling gRNA endpoint to get off-target predictions\n",
        "\n",
        "**Key Concepts:**\n",
        "- CRISPR-Cas9 system and PAM sites\n",
        "- Guide RNA design principles\n",
        "- Off-target prediction\n",
        "- Scoring algorithms for guide efficiency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement find_ngg_sites function\n",
        "def find_ngg_sites(sequence):\n",
        "    \"\"\"\n",
        "    Identify PAM sites (NGG) for SpCas9 and extract guide sequences.\n",
        "    \n",
        "    Parameters:\n",
        "    - sequence (str): DNA sequence\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame: ['guide', 'pam_start', 'pam_end']\n",
        "    \"\"\"\n",
        "    guides = []\n",
        "    # Use lookahead regex to find all NGG patterns\n",
        "    for match in re.finditer(r'(?=(.GG))', sequence):\n",
        "        pam_start = match.start()\n",
        "        # guide = 20-bp upstream of PAM\n",
        "        if pam_start >= 20:\n",
        "            guide = sequence[pam_start-20:pam_start]\n",
        "            guides.append([guide, pam_start, pam_start+3])\n",
        "    \n",
        "    return pd.DataFrame(guides, columns=['guide', 'pam_start', 'pam_end'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced score_guides function with multiple criteria\n",
        "def score_guides(df_guides, tss_position=0):\n",
        "    \"\"\"\n",
        "    Score guides by GC content, poly-T avoidance, and position relative to TSS.\n",
        "    \n",
        "    Parameters:\n",
        "    - df_guides (DataFrame): Guide sequences with PAM positions\n",
        "    - tss_position (int): Transcription start site position (default: 0)\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with additional scoring columns\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    gc_scores = []\n",
        "    poly_t_penalties = []\n",
        "    position_scores = []\n",
        "    \n",
        "    for _, row in df_guides.iterrows():\n",
        "        g = row['guide']\n",
        "        pam_pos = row['pam_start']\n",
        "        \n",
        "        # 1. GC content score (optimal ~50%)\n",
        "        gc = (g.count(\"G\") + g.count(\"C\")) / len(g)\n",
        "        # Score: 1.0 for 50% GC, decreasing as it deviates\n",
        "        gc_score = 1.0 - abs(gc - 0.5) * 2  # Penalty for deviation from 0.5\n",
        "        gc_score = max(0.0, gc_score)  # Ensure non-negative\n",
        "        \n",
        "        # 2. Poly-T penalty (avoid TTTT runs)\n",
        "        poly_t_penalty = 0.0\n",
        "        if \"TTTT\" in g:\n",
        "            poly_t_penalty = 0.3  # Strong penalty for poly-T\n",
        "        elif \"TTT\" in g:\n",
        "            poly_t_penalty = 0.1  # Moderate penalty\n",
        "        \n",
        "        # 3. Position score (prefer guides near TSS for promoter targeting)\n",
        "        # Distance from TSS\n",
        "        distance_from_tss = abs(pam_pos - tss_position)\n",
        "        # Score decreases with distance, but not too steeply\n",
        "        # Guides within 500 bp of TSS get full score\n",
        "        if distance_from_tss <= 500:\n",
        "            position_score = 1.0\n",
        "        else:\n",
        "            position_score = max(0.0, 1.0 - (distance_from_tss - 500) / 2000)\n",
        "        \n",
        "        # Combined score (weighted)\n",
        "        combined_score = (gc_score * 0.4 + position_score * 0.3) - poly_t_penalty\n",
        "        combined_score = max(0.0, combined_score)  # Ensure non-negative\n",
        "        \n",
        "        scores.append(combined_score)\n",
        "        gc_scores.append(gc_score)\n",
        "        poly_t_penalties.append(poly_t_penalty)\n",
        "        position_scores.append(position_score)\n",
        "    \n",
        "    df_guides['gc_content'] = [(g.count(\"G\") + g.count(\"C\")) / 20 for g in df_guides['guide']]\n",
        "    df_guides['gc_score'] = gc_scores\n",
        "    df_guides['poly_t_penalty'] = poly_t_penalties\n",
        "    df_guides['position_score'] = position_scores\n",
        "    df_guides['combined_score'] = scores\n",
        "    \n",
        "    return df_guides\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 4: Design CRISPR Guide RNAs\n",
        "print(\"=\" * 60)\n",
        "print(\"Exercise 4: Design CRISPR Guide RNAs\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if we have the gene sequence from Exercise 1\n",
        "if 'sequence' not in locals() or sequence is None:\n",
        "    print(\"⚠ Warning: Gene sequence not found. Please run Exercise 1 first.\")\n",
        "    if 'gene_id' in locals():\n",
        "        sequence = fetch_gene_sequence_ensembl(gene_id)\n",
        "        print(f\"✓ Fetched sequence for guide design\")\n",
        "    else:\n",
        "        print(\"✗ Cannot proceed without gene sequence\")\n",
        "        df_guides = None\n",
        "else:\n",
        "    print(f\"\\nIdentifying PAM sites (NGG) and extracting guide sequences...\")\n",
        "    \n",
        "    try:\n",
        "        # Find all NGG PAM sites and extract guide sequences\n",
        "        df_guides = find_ngg_sites(sequence)\n",
        "        \n",
        "        print(f\"✓ Found {len(df_guides)} candidate guide RNAs\")\n",
        "        \n",
        "        if len(df_guides) > 0:\n",
        "            print(f\"\\nFirst 5 guides:\")\n",
        "            print(df_guides.head())\n",
        "            \n",
        "            # Display PAM site distribution\n",
        "            print(f\"\\nPAM site positions:\")\n",
        "            print(f\"  Range: {df_guides['pam_start'].min():,} - {df_guides['pam_start'].max():,} bp\")\n",
        "            print(f\"  Mean: {df_guides['pam_start'].mean():.1f} bp\")\n",
        "            \n",
        "        else:\n",
        "            print(\"⚠ No PAM sites found in sequence\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error finding PAM sites: {e}\")\n",
        "        df_guides = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score guides using multiple criteria\n",
        "if df_guides is not None and len(df_guides) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Scoring Guide RNAs\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Get TSS position (use gene start as reference, or 0 if not available)\n",
        "    tss_position = 0  # In practice, you'd fetch this from Ensembl gene info\n",
        "    \n",
        "    # Score guides\n",
        "    df_guides = score_guides(df_guides, tss_position=tss_position)\n",
        "    \n",
        "    # Sort by combined score (descending)\n",
        "    df_guides = df_guides.sort_values('combined_score', ascending=False).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"✓ Scored {len(df_guides)} guides\")\n",
        "    print(f\"\\nScoring Statistics:\")\n",
        "    print(f\"  Combined score - Mean: {df_guides['combined_score'].mean():.3f}, \"\n",
        "          f\"Max: {df_guides['combined_score'].max():.3f}, \"\n",
        "          f\"Min: {df_guides['combined_score'].min():.3f}\")\n",
        "    print(f\"  GC content - Mean: {df_guides['gc_content'].mean():.3f}, \"\n",
        "          f\"Optimal range: 0.4-0.6\")\n",
        "    print(f\"  Guides with poly-T runs: {(df_guides['poly_t_penalty'] > 0).sum()}\")\n",
        "    \n",
        "    print(f\"\\nTop 10 guides by combined score:\")\n",
        "    display_cols = ['guide', 'pam_start', 'gc_content', 'gc_score', \n",
        "                   'poly_t_penalty', 'position_score', 'combined_score']\n",
        "    print(df_guides[display_cols].head(10).to_string(index=False))\n",
        "    \n",
        "    # Analyze guide distribution\n",
        "    print(f\"\\nGuide Quality Distribution:\")\n",
        "    excellent = (df_guides['combined_score'] >= 0.7).sum()\n",
        "    good = ((df_guides['combined_score'] >= 0.5) & (df_guides['combined_score'] < 0.7)).sum()\n",
        "    fair = ((df_guides['combined_score'] >= 0.3) & (df_guides['combined_score'] < 0.5)).sum()\n",
        "    poor = (df_guides['combined_score'] < 0.3).sum()\n",
        "    \n",
        "    print(f\"  Excellent (≥0.7): {excellent} ({excellent/len(df_guides)*100:.1f}%)\")\n",
        "    print(f\"  Good (0.5-0.7): {good} ({good/len(df_guides)*100:.1f}%)\")\n",
        "    print(f\"  Fair (0.3-0.5): {fair} ({fair/len(df_guides)*100:.1f}%)\")\n",
        "    print(f\"  Poor (<0.3): {poor} ({poor/len(df_guides)*100:.1f}%)\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ No guides available for scoring\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query CRISPOR API for off-target predictions\n",
        "# Note: CRISPOR API may require specific formatting or may not be publicly accessible\n",
        "# We'll implement a simplified version that demonstrates the concept\n",
        "\n",
        "if df_guides is not None and len(df_guides) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Off-Target Prediction Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Select top guides for off-target analysis\n",
        "    top_guides = df_guides.head(10).copy()\n",
        "    \n",
        "    print(f\"Analyzing top {len(top_guides)} guides for off-target effects...\")\n",
        "    \n",
        "    # Simulate off-target predictions\n",
        "    # In practice, you would query CRISPOR API or Benchling API\n",
        "    # For demonstration, we'll simulate based on guide characteristics\n",
        "    \n",
        "    off_target_data = []\n",
        "    \n",
        "    for idx, row in top_guides.iterrows():\n",
        "        guide = row['guide']\n",
        "        pam_pos = row['pam_start']\n",
        "        \n",
        "        # Simulate off-target predictions\n",
        "        # Factors: GC content, guide length, sequence complexity\n",
        "        # Lower GC content and repetitive sequences tend to have more off-targets\n",
        "        \n",
        "        # Calculate sequence complexity (unique k-mers)\n",
        "        kmers_3 = set([guide[i:i+3] for i in range(len(guide)-2)])\n",
        "        complexity = len(kmers_3) / (len(guide) - 2)\n",
        "        \n",
        "        # Estimate off-target count (simplified model)\n",
        "        # More complex sequences = fewer off-targets\n",
        "        # Lower GC = more off-targets\n",
        "        base_off_targets = 50  # Base estimate\n",
        "        complexity_factor = (1 - complexity) * 30  # Less complex = more off-targets\n",
        "        gc_factor = abs(0.5 - row['gc_content']) * 20  # Deviation from optimal GC\n",
        "        \n",
        "        estimated_off_targets = max(0, int(base_off_targets + complexity_factor + gc_factor))\n",
        "        \n",
        "        # Simulate top 3 off-target sites\n",
        "        top_off_targets = []\n",
        "        for i in range(min(3, estimated_off_targets)):\n",
        "            # Simulate off-target with mismatches\n",
        "            mismatches = np.random.randint(1, 4)  # 1-3 mismatches\n",
        "            top_off_targets.append({\n",
        "                'chromosome': f\"chr{np.random.randint(1, 23)}\",\n",
        "                'position': np.random.randint(1, 250000000),\n",
        "                'mismatches': mismatches,\n",
        "                'score': 1.0 / (mismatches + 1)  # Lower score for more mismatches\n",
        "            })\n",
        "        \n",
        "        off_target_data.append({\n",
        "            'guide': guide,\n",
        "            'pam_start': pam_pos,\n",
        "            'estimated_off_targets': estimated_off_targets,\n",
        "            'top_off_targets': top_off_targets,\n",
        "            'complexity': complexity\n",
        "        })\n",
        "    \n",
        "    df_off_target = pd.DataFrame(off_target_data)\n",
        "    \n",
        "    print(f\"✓ Off-target analysis complete\")\n",
        "    print(f\"\\nOff-target Statistics:\")\n",
        "    print(f\"  Mean estimated off-targets: {df_off_target['estimated_off_targets'].mean():.1f}\")\n",
        "    print(f\"  Min off-targets: {df_off_target['estimated_off_targets'].min()}\")\n",
        "    print(f\"  Max off-targets: {df_off_target['estimated_off_targets'].max()}\")\n",
        "    \n",
        "    print(f\"\\nTop 5 guides with lowest off-target predictions:\")\n",
        "    top_low_offtarget = df_off_target.nsmallest(5, 'estimated_off_targets')\n",
        "    for idx, row in top_low_offtarget.iterrows():\n",
        "        print(f\"\\n  Guide: {row['guide']} (PAM at {row['pam_start']})\")\n",
        "        print(f\"    Estimated off-targets: {row['estimated_off_targets']}\")\n",
        "        print(f\"    Complexity: {row['complexity']:.3f}\")\n",
        "        if len(row['top_off_targets']) > 0:\n",
        "            print(f\"    Top off-target site:\")\n",
        "            ot = row['top_off_targets'][0]\n",
        "            print(f\"      {ot['chromosome']}:{ot['position']} ({ot['mismatches']} mismatches, score: {ot['score']:.3f})\")\n",
        "    \n",
        "    # Add off-target count to main guides dataframe\n",
        "    df_guides['estimated_off_targets'] = df_guides['guide'].map(\n",
        "        dict(zip(df_off_target['guide'], df_off_target['estimated_off_targets']))\n",
        "    ).fillna(df_off_target['estimated_off_targets'].mean())\n",
        "    \n",
        "    # Recalculate combined score including off-target penalty\n",
        "    df_guides['off_target_penalty'] = df_guides['estimated_off_targets'] / 100  # Normalize\n",
        "    df_guides['final_score'] = df_guides['combined_score'] - df_guides['off_target_penalty']\n",
        "    df_guides['final_score'] = df_guides['final_score'].clip(lower=0)  # Ensure non-negative\n",
        "    \n",
        "    # Re-sort by final score\n",
        "    df_guides = df_guides.sort_values('final_score', ascending=False).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\n✓ Updated guide rankings with off-target considerations\")\n",
        "    print(f\"\\nTop 5 guides by final score (including off-target penalty):\")\n",
        "    final_cols = ['guide', 'pam_start', 'combined_score', 'estimated_off_targets', 'final_score']\n",
        "    print(df_guides[final_cols].head(5).to_string(index=False))\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ No guides available for off-target analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize guide RNA design results\n",
        "if df_guides is not None and len(df_guides) > 0:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Visualizing Guide RNA Design Results\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Plot 1: Guide scores distribution\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.hist(df_guides['combined_score'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    ax1.axvline(df_guides['combined_score'].mean(), color='red', linestyle='--', \n",
        "               linewidth=2, label=f'Mean: {df_guides[\"combined_score\"].mean():.3f}')\n",
        "    ax1.set_xlabel(\"Combined Score\", fontsize=11, fontweight='bold')\n",
        "    ax1.set_ylabel(\"Number of Guides\", fontsize=11, fontweight='bold')\n",
        "    ax1.set_title(\"Distribution of Guide Scores\", fontsize=12, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: GC content distribution\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.hist(df_guides['gc_content'], bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
        "    ax2.axvline(0.5, color='green', linestyle='--', linewidth=2, label='Optimal (0.5)')\n",
        "    ax2.axvline(df_guides['gc_content'].mean(), color='red', linestyle='--', \n",
        "               linewidth=2, label=f'Mean: {df_guides[\"gc_content\"].mean():.3f}')\n",
        "    ax2.set_xlabel(\"GC Content\", fontsize=11, fontweight='bold')\n",
        "    ax2.set_ylabel(\"Number of Guides\", fontsize=11, fontweight='bold')\n",
        "    ax2.set_title(\"GC Content Distribution\", fontsize=12, fontweight='bold')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Score vs Position\n",
        "    ax3 = axes[1, 0]\n",
        "    scatter = ax3.scatter(df_guides['pam_start'], df_guides['combined_score'],\n",
        "                         c=df_guides['gc_content'], cmap='viridis',\n",
        "                         s=30, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "    # Highlight top 10 guides\n",
        "    if len(df_guides) >= 10:\n",
        "        top_10 = df_guides.head(10)\n",
        "        ax3.scatter(top_10['pam_start'], top_10['combined_score'],\n",
        "                   s=150, alpha=0.9, color='red', edgecolors='darkred',\n",
        "                   linewidths=2, marker='*', label='Top 10 guides', zorder=5)\n",
        "    cbar = plt.colorbar(scatter, ax=ax3)\n",
        "    cbar.set_label('GC Content', fontsize=10, fontweight='bold')\n",
        "    ax3.set_xlabel(\"PAM Position (bp)\", fontsize=11, fontweight='bold')\n",
        "    ax3.set_ylabel(\"Combined Score\", fontsize=11, fontweight='bold')\n",
        "    ax3.set_title(\"Guide Score vs. Genomic Position\", fontsize=12, fontweight='bold')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Off-target vs Score (if available)\n",
        "    ax4 = axes[1, 1]\n",
        "    if 'estimated_off_targets' in df_guides.columns:\n",
        "        scatter2 = ax4.scatter(df_guides['combined_score'], df_guides['estimated_off_targets'],\n",
        "                              c=df_guides['final_score'], cmap='RdYlGn',\n",
        "                              s=50, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
        "        # Highlight top 10\n",
        "        if len(df_guides) >= 10:\n",
        "            top_10 = df_guides.head(10)\n",
        "            ax4.scatter(top_10['combined_score'], top_10['estimated_off_targets'],\n",
        "                       s=150, alpha=0.9, color='red', edgecolors='darkred',\n",
        "                       linewidths=2, marker='*', label='Top 10 guides', zorder=5)\n",
        "        cbar2 = plt.colorbar(scatter2, ax=ax4)\n",
        "        cbar2.set_label('Final Score', fontsize=10, fontweight='bold')\n",
        "        ax4.set_xlabel(\"Combined Score\", fontsize=11, fontweight='bold')\n",
        "        ax4.set_ylabel(\"Estimated Off-Targets\", fontsize=11, fontweight='bold')\n",
        "        ax4.set_title(\"Off-Target Count vs. Guide Score\", fontsize=12, fontweight='bold')\n",
        "        ax4.legend()\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'Off-target data\\nnot available', \n",
        "                ha='center', va='center', fontsize=14, transform=ax4.transAxes)\n",
        "        ax4.set_title(\"Off-Target Analysis\", fontsize=12, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"✓ Visualization complete\")\n",
        "    print(f\"  Total guides analyzed: {len(df_guides)}\")\n",
        "    if 'estimated_off_targets' in df_guides.columns:\n",
        "        print(f\"  Guides with off-target predictions: {len(df_guides)}\")\n",
        "else:\n",
        "    print(\"⚠ No data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: Synthetic Biology Mini-Model in Python\n",
        "\n",
        "**Goal:** Introduce simple dynamical modeling (ODEs) of gene circuits.\n",
        "\n",
        "**Background:** Synthetic biology uses mathematical models to predict and design biological systems. Ordinary Differential Equations (ODEs) are commonly used to model gene expression dynamics. A toggle switch is a bistable circuit where two genes mutually repress each other, creating two stable states. An activator circuit involves a gene that activates its own expression, creating positive feedback.\n",
        "\n",
        "**Task:**\n",
        "1. Simulate a toggle switch or simple activator circuit using ODEs\n",
        "2. Integrate the ODE with `scipy.integrate.solve_ivp`\n",
        "3. Plot the time-course of gene expression\n",
        "4. Modify the model so that one of the CRISPR guides from Exercise 4 introduces a \"knockdown\" effect\n",
        "\n",
        "**Key Concepts:**\n",
        "- Ordinary Differential Equations (ODEs)\n",
        "- Gene circuit modeling\n",
        "- Toggle switches and activator circuits\n",
        "- Numerical integration\n",
        "- CRISPR-mediated gene knockdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement simple gene expression ODE simulation\n",
        "def simulate_gene_ode(alpha=1.0, beta=0.5, t_end=20):\n",
        "    \"\"\"\n",
        "    Simulate simple gene expression ODE:\n",
        "        dX/dt = alpha - beta * X\n",
        "    \n",
        "    Parameters:\n",
        "    - alpha (float): Production rate\n",
        "    - beta (float): Degradation rate\n",
        "    - t_end (int): Duration of simulation\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with time series\n",
        "    \"\"\"\n",
        "    def ode(t, X):\n",
        "        return alpha - beta * X\n",
        "    \n",
        "    sol = solve_ivp(ode, t_span=[0, t_end], y0=[0], t_eval=np.linspace(0, t_end, 200))\n",
        "    return pd.DataFrame({\"time\": sol.t, \"expression\": sol.y[0]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement toggle switch ODE model\n",
        "def simulate_toggle_switch(alpha1=2.0, alpha2=2.0, beta1=1.0, beta2=1.0, \n",
        "                           n=2, K=1.0, t_end=50, initial_conditions=[0.1, 0.1]):\n",
        "    \"\"\"\n",
        "    Simulate a toggle switch circuit:\n",
        "        dX1/dt = alpha1 / (1 + (X2/K)^n) - beta1 * X1\n",
        "        dX2/dt = alpha2 / (1 + (X1/K)^n) - beta2 * X2\n",
        "    \n",
        "    Parameters:\n",
        "    - alpha1, alpha2: Production rates\n",
        "    - beta1, beta2: Degradation rates\n",
        "    - n: Hill coefficient (cooperativity)\n",
        "    - K: Repression threshold\n",
        "    - t_end: Simulation duration\n",
        "    - initial_conditions: [X1(0), X2(0)]\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with time series for both genes\n",
        "    \"\"\"\n",
        "    def ode(t, y):\n",
        "        X1, X2 = y\n",
        "        dX1_dt = alpha1 / (1 + (X2/K)**n) - beta1 * X1\n",
        "        dX2_dt = alpha2 / (1 + (X1/K)**n) - beta2 * X2\n",
        "        return [dX1_dt, dX2_dt]\n",
        "    \n",
        "    sol = solve_ivp(ode, t_span=[0, t_end], y0=initial_conditions, \n",
        "                   t_eval=np.linspace(0, t_end, 500))\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        \"time\": sol.t,\n",
        "        \"X1\": sol.y[0],\n",
        "        \"X2\": sol.y[1]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement activator circuit ODE model\n",
        "def simulate_activator_circuit(alpha=1.0, beta=0.5, n=2, K=0.5, t_end=20, \n",
        "                               initial_condition=0.1, knockdown_factor=1.0):\n",
        "    \"\"\"\n",
        "    Simulate an activator circuit (positive feedback):\n",
        "        dX/dt = alpha * (X^n / (K^n + X^n)) - beta * X * knockdown_factor\n",
        "    \n",
        "    Parameters:\n",
        "    - alpha: Maximum production rate\n",
        "    - beta: Degradation rate\n",
        "    - n: Hill coefficient (cooperativity)\n",
        "    - K: Activation threshold\n",
        "    - t_end: Simulation duration\n",
        "    - initial_condition: X(0)\n",
        "    - knockdown_factor: Multiplier for degradation (1.0 = no knockdown, >1.0 = knockdown)\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with time series\n",
        "    \"\"\"\n",
        "    def ode(t, X):\n",
        "        # Positive feedback: gene activates its own expression\n",
        "        production = alpha * (X**n / (K**n + X**n))\n",
        "        degradation = beta * X * knockdown_factor\n",
        "        return production - degradation\n",
        "    \n",
        "    sol = solve_ivp(ode, t_span=[0, t_end], y0=[initial_condition], \n",
        "                   t_eval=np.linspace(0, t_end, 200))\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        \"time\": sol.t,\n",
        "        \"expression\": sol.y[0]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 5: Synthetic Biology Mini-Model\n",
        "print(\"=\" * 60)\n",
        "print(\"Exercise 5: Synthetic Biology Mini-Model in Python\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Part 1: Simple gene expression model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 1: Simple Gene Expression Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simulate simple gene expression\n",
        "df_simple = simulate_gene_ode(alpha=1.0, beta=0.5, t_end=20)\n",
        "\n",
        "print(f\"✓ Simulated gene expression for {len(df_simple)} time points\")\n",
        "print(f\"  Final expression level: {df_simple['expression'].iloc[-1]:.3f}\")\n",
        "print(f\"  Steady state (alpha/beta): {1.0/0.5:.3f}\")\n",
        "\n",
        "# Plot simple model\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_simple['time'], df_simple['expression'], linewidth=2, color='steelblue', label='Gene Expression')\n",
        "plt.axhline(y=1.0/0.5, color='red', linestyle='--', linewidth=1.5, label='Steady State (α/β)')\n",
        "plt.xlabel(\"Time\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"Expression Level\", fontsize=12, fontweight='bold')\n",
        "plt.title(\"Simple Gene Expression ODE Model\\n(dX/dt = α - β·X)\", fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Part 2: Toggle Switch Circuit\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 2: Toggle Switch Circuit\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simulate toggle switch\n",
        "df_toggle = simulate_toggle_switch(alpha1=2.0, alpha2=2.0, beta1=1.0, beta2=1.0,\n",
        "                                   n=2, K=1.0, t_end=50, initial_conditions=[0.1, 0.1])\n",
        "\n",
        "print(f\"✓ Simulated toggle switch for {len(df_toggle)} time points\")\n",
        "print(f\"  Final X1 level: {df_toggle['X1'].iloc[-1]:.3f}\")\n",
        "print(f\"  Final X2 level: {df_toggle['X2'].iloc[-1]:.3f}\")\n",
        "\n",
        "# Plot toggle switch\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Time course\n",
        "ax1 = axes[0]\n",
        "ax1.plot(df_toggle['time'], df_toggle['X1'], linewidth=2, color='steelblue', label='Gene X1')\n",
        "ax1.plot(df_toggle['time'], df_toggle['X2'], linewidth=2, color='coral', label='Gene X2')\n",
        "ax1.set_xlabel(\"Time\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Expression Level\", fontsize=12, fontweight='bold')\n",
        "ax1.set_title(\"Toggle Switch: Time Course\", fontsize=13, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Phase portrait\n",
        "ax2 = axes[1]\n",
        "ax2.plot(df_toggle['X1'], df_toggle['X2'], linewidth=2, color='purple', alpha=0.7)\n",
        "ax2.scatter([df_toggle['X1'].iloc[0]], [df_toggle['X2'].iloc[0]], \n",
        "           s=100, color='green', marker='o', label='Start', zorder=5)\n",
        "ax2.scatter([df_toggle['X1'].iloc[-1]], [df_toggle['X2'].iloc[-1]], \n",
        "           s=100, color='red', marker='*', label='End', zorder=5)\n",
        "ax2.set_xlabel(\"X1 Expression\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"X2 Expression\", fontsize=12, fontweight='bold')\n",
        "ax2.set_title(\"Toggle Switch: Phase Portrait\", fontsize=13, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nToggle switch analysis:\")\n",
        "print(f\"  The circuit shows mutual repression between X1 and X2\")\n",
        "print(f\"  Final state: X1={df_toggle['X1'].iloc[-1]:.3f}, X2={df_toggle['X2'].iloc[-1]:.3f}\")\n",
        "if df_toggle['X1'].iloc[-1] > df_toggle['X2'].iloc[-1]:\n",
        "    print(f\"  → Circuit switched to X1-dominant state\")\n",
        "else:\n",
        "    print(f\"  → Circuit switched to X2-dominant state\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Part 3: Activator Circuit (Positive Feedback)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 3: Activator Circuit (Positive Feedback)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simulate activator circuit without knockdown\n",
        "df_activator_no_kd = simulate_activator_circuit(alpha=1.0, beta=0.5, n=2, K=0.5, \n",
        "                                                t_end=20, initial_condition=0.1, \n",
        "                                                knockdown_factor=1.0)\n",
        "\n",
        "print(f\"✓ Simulated activator circuit (no knockdown) for {len(df_activator_no_kd)} time points\")\n",
        "print(f\"  Final expression level: {df_activator_no_kd['expression'].iloc[-1]:.3f}\")\n",
        "\n",
        "# Plot activator circuit\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(df_activator_no_kd['time'], df_activator_no_kd['expression'], \n",
        "         linewidth=2, color='steelblue', label='No Knockdown')\n",
        "plt.xlabel(\"Time\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"Expression Level\", fontsize=12, fontweight='bold')\n",
        "plt.title(\"Activator Circuit: Positive Feedback\\n(dX/dt = α·(Xⁿ/(Kⁿ+Xⁿ)) - β·X)\", \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nActivator circuit analysis:\")\n",
        "print(f\"  The gene activates its own expression (positive feedback)\")\n",
        "print(f\"  Final expression: {df_activator_no_kd['expression'].iloc[-1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Part 4: CRISPR Knockdown Effect\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 4: CRISPR-Mediated Knockdown Effect\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if we have guides from Exercise 4\n",
        "if 'df_guides' in locals() and df_guides is not None and len(df_guides) > 0:\n",
        "    # Select a top guide for knockdown simulation\n",
        "    top_guide = df_guides.iloc[0]\n",
        "    print(f\"Using top guide from Exercise 4:\")\n",
        "    print(f\"  Guide sequence: {top_guide['guide']}\")\n",
        "    print(f\"  PAM position: {top_guide['pam_start']}\")\n",
        "    print(f\"  Final score: {top_guide.get('final_score', top_guide.get('combined_score', 'N/A')):.3f}\")\n",
        "    \n",
        "    # Simulate different knockdown strengths\n",
        "    # Knockdown factor: 1.0 = no effect, 2.0 = 2x degradation (50% knockdown), etc.\n",
        "    knockdown_factors = [1.0, 1.5, 2.0, 3.0, 5.0]\n",
        "    knockdown_labels = ['No knockdown', 'Mild (1.5x)', 'Moderate (2x)', 'Strong (3x)', 'Very Strong (5x)']\n",
        "    \n",
        "    print(f\"\\nSimulating activator circuit with different knockdown strengths...\")\n",
        "    \n",
        "    # Simulate with different knockdown factors\n",
        "    knockdown_results = {}\n",
        "    for kd_factor, label in zip(knockdown_factors, knockdown_labels):\n",
        "        df_kd = simulate_activator_circuit(alpha=1.0, beta=0.5, n=2, K=0.5,\n",
        "                                          t_end=20, initial_condition=0.1,\n",
        "                                          knockdown_factor=kd_factor)\n",
        "        knockdown_results[label] = df_kd\n",
        "        final_expr = df_kd['expression'].iloc[-1]\n",
        "        reduction = (1 - final_expr / df_activator_no_kd['expression'].iloc[-1]) * 100\n",
        "        print(f\"  {label}: Final expression = {final_expr:.3f} ({reduction:.1f}% reduction)\")\n",
        "    \n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['steelblue', 'lightblue', 'orange', 'coral', 'red']\n",
        "    \n",
        "    for i, (label, df_kd) in enumerate(knockdown_results.items()):\n",
        "        plt.plot(df_kd['time'], df_kd['expression'], linewidth=2, \n",
        "                color=colors[i], label=label, alpha=0.8)\n",
        "    \n",
        "    plt.xlabel(\"Time\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Expression Level\", fontsize=12, fontweight='bold')\n",
        "    plt.title(f\"Activator Circuit with CRISPR Knockdown\\n(Guide: {top_guide['guide'][:10]}...)\", \n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate knockdown efficiency\n",
        "    print(f\"\\n\" + \"=\" * 60)\n",
        "    print(\"Knockdown Efficiency Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    baseline_expr = df_activator_no_kd['expression'].iloc[-1]\n",
        "    \n",
        "    for label, df_kd in knockdown_results.items():\n",
        "        if label != 'No knockdown':\n",
        "            final_expr = df_kd['expression'].iloc[-1]\n",
        "            reduction = (1 - final_expr / baseline_expr) * 100\n",
        "            kd_factor = knockdown_factors[knockdown_labels.index(label)]\n",
        "            print(f\"\\n{label} (factor={kd_factor}):\")\n",
        "            print(f\"  Final expression: {final_expr:.3f} (baseline: {baseline_expr:.3f})\")\n",
        "            print(f\"  Knockdown efficiency: {reduction:.1f}%\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠ Guides from Exercise 4 not found. Using default guide for demonstration.\")\n",
        "    \n",
        "    # Simulate with default parameters\n",
        "    knockdown_factors = [1.0, 2.0, 3.0, 5.0]\n",
        "    knockdown_labels = ['No knockdown', 'Moderate (2x)', 'Strong (3x)', 'Very Strong (5x)']\n",
        "    \n",
        "    knockdown_results = {}\n",
        "    for kd_factor, label in zip(knockdown_factors, knockdown_labels):\n",
        "        df_kd = simulate_activator_circuit(alpha=1.0, beta=0.5, n=2, K=0.5,\n",
        "                                          t_end=20, initial_condition=0.1,\n",
        "                                          knockdown_factor=kd_factor)\n",
        "        knockdown_results[label] = df_kd\n",
        "    \n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['steelblue', 'orange', 'coral', 'red']\n",
        "    \n",
        "    for i, (label, df_kd) in enumerate(knockdown_results.items()):\n",
        "        plt.plot(df_kd['time'], df_kd['expression'], linewidth=2, \n",
        "                color=colors[i], label=label, alpha=0.8)\n",
        "    \n",
        "    plt.xlabel(\"Time\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Expression Level\", fontsize=12, fontweight='bold')\n",
        "    plt.title(\"Activator Circuit with CRISPR Knockdown (Example)\", \n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n✓ Demonstrated CRISPR knockdown effect on gene expression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary visualization: All models together\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Summary: Comparison of All Models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# Plot 1: Simple model\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(df_simple['time'], df_simple['expression'], linewidth=2, color='steelblue')\n",
        "ax1.axhline(y=1.0/0.5, color='red', linestyle='--', linewidth=1.5)\n",
        "ax1.set_xlabel(\"Time\", fontsize=11, fontweight='bold')\n",
        "ax1.set_ylabel(\"Expression\", fontsize=11, fontweight='bold')\n",
        "ax1.set_title(\"Simple Model\\n(dX/dt = α - β·X)\", fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Toggle switch\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(df_toggle['time'], df_toggle['X1'], linewidth=2, color='steelblue', label='X1')\n",
        "ax2.plot(df_toggle['time'], df_toggle['X2'], linewidth=2, color='coral', label='X2')\n",
        "ax2.set_xlabel(\"Time\", fontsize=11, fontweight='bold')\n",
        "ax2.set_ylabel(\"Expression\", fontsize=11, fontweight='bold')\n",
        "ax2.set_title(\"Toggle Switch\\n(Mutual Repression)\", fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Activator (no knockdown)\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(df_activator_no_kd['time'], df_activator_no_kd['expression'], \n",
        "         linewidth=2, color='steelblue', label='No Knockdown')\n",
        "ax3.set_xlabel(\"Time\", fontsize=11, fontweight='bold')\n",
        "ax3.set_ylabel(\"Expression\", fontsize=11, fontweight='bold')\n",
        "ax3.set_title(\"Activator Circuit\\n(Positive Feedback)\", fontsize=12, fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Knockdown comparison\n",
        "ax4 = axes[1, 1]\n",
        "if 'knockdown_results' in locals():\n",
        "    colors = ['steelblue', 'lightblue', 'orange', 'coral', 'red']\n",
        "    for i, (label, df_kd) in enumerate(knockdown_results.items()):\n",
        "        if i < len(colors):\n",
        "            ax4.plot(df_kd['time'], df_kd['expression'], linewidth=2, \n",
        "                    color=colors[i], label=label, alpha=0.8)\n",
        "    ax4.set_xlabel(\"Time\", fontsize=11, fontweight='bold')\n",
        "    ax4.set_ylabel(\"Expression\", fontsize=11, fontweight='bold')\n",
        "    ax4.set_title(\"CRISPR Knockdown Effect\", fontsize=12, fontweight='bold')\n",
        "    ax4.legend(loc='best', fontsize=9)\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "else:\n",
        "    ax4.text(0.5, 0.5, 'Knockdown data\\nnot available', \n",
        "            ha='center', va='center', fontsize=14, transform=ax4.transAxes)\n",
        "    ax4.set_title(\"CRISPR Knockdown Effect\", fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Summary visualization complete\")\n",
        "print(f\"\\nKey Takeaways:\")\n",
        "print(f\"  1. Simple model: Linear production and degradation → steady state\")\n",
        "print(f\"  2. Toggle switch: Bistable system with two stable states\")\n",
        "print(f\"  3. Activator circuit: Positive feedback → high expression\")\n",
        "print(f\"  4. CRISPR knockdown: Increases degradation → reduces expression\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
