{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomics Laboratory\n",
    "## Student Notebook\n",
    "\n",
    "This notebook contains exercises for the Genomics laboratory session. Complete each exercise by following the step-by-step instructions and filling in the code stubs.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Retrieve genomic data from public databases using REST APIs\n",
    "- Analyze DNA sequences and compute basic statistics\n",
    "- Work with genetic variants and their annotations\n",
    "- Integrate multi-omics data (genomics, epigenomics)\n",
    "- Design CRISPR guide RNAs\n",
    "- Model gene expression dynamics using ODEs\n",
    "\n",
    "**Instructions:**\n",
    "- Read each exercise description carefully\n",
    "- Follow the step-by-step instructions\n",
    "- Fill in the code stubs marked with `# TODO:` comments\n",
    "- Run each cell and verify your results\n",
    "- Ask for help if you get stuck!\n",
    "\n",
    "---\n",
    "\n",
    "## Laboratory Pipeline Overview\n",
    "\n",
    "This laboratory session follows a complete bioinformatics analysis pipeline:\n",
    "\n",
    "1. **Exercise 1: Retrieve Gene Sequence**\n",
    "   - Fetch genomic sequence from Ensembl REST API\n",
    "   - Compute basic sequence statistics (GC content, CpG motifs, length)\n",
    "   - Visualize GC content along the sequence\n",
    "\n",
    "2. **Exercise 2: Fetch Variants**\n",
    "   - Retrieve known genetic variants (SNPs/INDELs) from Ensembl Variation API\n",
    "   - Plot variant distribution along the gene\n",
    "   - Annotate variant impact\n",
    "\n",
    "3. **Exercise 3: Fetch Methylation Data**\n",
    "   - Query ENCODE database for whole-genome bisulfite sequencing (WGBS) data\n",
    "   - Understand epigenomic datasets\n",
    "\n",
    "4. **Exercise 4: Merge Variant + Methylation Data**\n",
    "   - Integrate variant positions with methylation scores\n",
    "   - Identify regulatory SNPs (variants in high-methylation zones)\n",
    "\n",
    "5. **Exercise 5: CRISPR Guide Design**\n",
    "   - Identify PAM sites (NGG) for SpCas9\n",
    "   - Design and score guide RNAs using heuristics\n",
    "\n",
    "6. **Exercise 6: Synthetic Gene Circuit Simulation**\n",
    "   - Model gene expression using ordinary differential equations (ODEs)\n",
    "   - Simulate dynamic behavior of gene circuits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.integrate import solve_ivp\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set up output directory\n",
    "output_dir = \"lab_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Retrieve Gene Sequence Using an API\n",
    "\n",
    "**Goal:** Teach API usage, JSON parsing, and basic bioinformatics manipulation.\n",
    "\n",
    "**Background:** The Ensembl REST API provides programmatic access to genomic data including DNA sequences, gene annotations, and variant information. This exercise introduces you to working with REST APIs in bioinformatics.\n",
    "\n",
    "**Task List:**\n",
    "1. Implement the `fetch_gene_sequence_ensembl` function:\n",
    "   - Construct the API URL using the Ensembl REST API endpoint\n",
    "   - Make an HTTP GET request\n",
    "   - Check if the request was successful\n",
    "   - Parse the JSON response\n",
    "   - Extract and return the sequence in uppercase\n",
    "2. Choose a gene to analyze (e.g., TP53, BRCA1, or TERT)\n",
    "3. Fetch the gene sequence using your function\n",
    "4. Store the sequence in FASTA format:\n",
    "   - Create a FASTA header line (starts with \">\")\n",
    "   - Format the sequence with line breaks (60 characters per line)\n",
    "   - Save to a file\n",
    "5. Compute basic sequence statistics:\n",
    "   - Calculate sequence length\n",
    "   - Calculate overall GC content\n",
    "   - Count CpG motifs\n",
    "   - Count each nucleotide (A, T, G, C)\n",
    "6. Implement `compute_gc_content` function:\n",
    "   - Use a sliding window approach\n",
    "   - Calculate GC content for each window\n",
    "   - Return a DataFrame with start, end, and gc_content columns\n",
    "7. Compute GC content using a sliding window\n",
    "8. Visualize GC content along the sequence:\n",
    "   - Plot GC content vs. genomic position\n",
    "   - Add a horizontal line for overall GC content\n",
    "   - Add labels and title\n",
    "\n",
    "**Key Concepts:**\n",
    "- REST API usage for biological databases\n",
    "- JSON parsing and data extraction\n",
    "- DNA sequence analysis\n",
    "- Sliding window operations\n",
    "- FASTA file format\n",
    "\n",
    "**Useful Ensembl Gene IDs:**\n",
    "- TP53: `ENSG00000141510`\n",
    "- BRCA1: `ENSG00000012048`\n",
    "- TERT: `ENSG00000164362`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement fetch_gene_sequence_ensembl function\n",
    "def fetch_gene_sequence_ensembl(gene_id):\n",
    "    \"\"\"\n",
    "    Fetch DNA sequence for a given human gene using Ensembl REST API.\n",
    "    \n",
    "    Parameters:\n",
    "    - gene_id (str): Ensembl gene ID (e.g., \"ENSG00000141510\" for TP53)\n",
    "    \n",
    "    Returns:\n",
    "    - str: Gene sequence in uppercase A/C/G/T\n",
    "    \n",
    "    Hint: Use the Ensembl REST API endpoint:\n",
    "    https://rest.ensembl.org/sequence/id/{gene_id}?content-type=application/json\n",
    "    \"\"\"\n",
    "    # TODO: Construct the API URL\n",
    "    url = None  # Fill in the URL\n",
    "    \n",
    "    # TODO: Make the API request\n",
    "    response = None  # Use requests.get()\n",
    "    \n",
    "    # TODO: Check if request was successful\n",
    "    # Use response.ok or response.raise_for_status()\n",
    "    \n",
    "    # TODO: Parse JSON response\n",
    "    data = None  # Use response.json()\n",
    "    \n",
    "    # TODO: Extract sequence and convert to uppercase\n",
    "    seq = None  # Get 'seq' from data and convert to uppercase\n",
    "    \n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Retrieve Gene Sequence\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 1: Retrieve Gene Sequence Using Ensembl API\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Choose a gene to analyze\n",
    "# Options: TP53 (ENSG00000141510), BRCA1 (ENSG00000012048), TERT (ENSG00000164362)\n",
    "gene_id = None  # Fill in an Ensembl gene ID\n",
    "gene_name = None  # Fill in the gene name (e.g., \"TP53\")\n",
    "\n",
    "print(f\"\\nFetching sequence for {gene_name} ({gene_id})...\")\n",
    "\n",
    "try:\n",
    "    # TODO: Fetch the gene sequence using fetch_gene_sequence_ensembl\n",
    "    sequence = None\n",
    "    \n",
    "    print(f\"✓ Successfully retrieved sequence\")\n",
    "    print(f\"  Sequence length: {len(sequence):,} bp\")\n",
    "    print(f\"  First 50 bases: {sequence[:50]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error fetching sequence: {e}\")\n",
    "    sequence = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Store sequence as FASTA format\n",
    "if sequence is not None:\n",
    "    # TODO: Create FASTA format string\n",
    "    # FASTA format: first line starts with \">\", followed by description\n",
    "    # Subsequent lines contain the sequence (typically 60-80 characters per line)\n",
    "    fasta_header = None  # Format: f\">{gene_id} {gene_name}\"\n",
    "    \n",
    "    # TODO: Format sequence with line breaks (every 60 characters)\n",
    "    fasta_sequence = None  # Use list comprehension or loop\n",
    "    \n",
    "    # TODO: Combine header and sequence\n",
    "    fasta_content = None\n",
    "    \n",
    "    # TODO: Save to file\n",
    "    fasta_filename = None  # e.g., f\"{output_dir}/{gene_name}_sequence.fasta\"\n",
    "    # TODO: Write fasta_content to file using open() and write()\n",
    "    \n",
    "    print(f\"✓ Sequence saved to {fasta_filename}\")\n",
    "    print(f\"\\nFASTA preview:\")\n",
    "    print(fasta_content[:200] + \"...\" if len(fasta_content) > 200 else fasta_content)\n",
    "else:\n",
    "    print(\"⚠ No sequence available to save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute basic sequence statistics\n",
    "if sequence is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Basic Sequence Statistics\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Calculate sequence length\n",
    "    seq_length = None  # Use len(sequence)\n",
    "    \n",
    "    # TODO: Calculate overall GC content\n",
    "    # GC content = (G + C) / total_length\n",
    "    g_count = None  # Count 'G' in sequence\n",
    "    c_count = None  # Count 'C' in sequence\n",
    "    gc_count = None  # Sum of G and C\n",
    "    gc_content = None  # Calculate percentage\n",
    "    \n",
    "    # TODO: Count CpG motifs\n",
    "    # CpG motif = \"CG\" dinucleotide\n",
    "    cpg_count = None  # Count occurrences of \"CG\" in sequence\n",
    "    cpg_density = None  # CpG count per 1000 bp\n",
    "    \n",
    "    # TODO: Count each nucleotide\n",
    "    a_count = None  # Count 'A'\n",
    "    t_count = None  # Count 'T'\n",
    "    \n",
    "    # TODO: Print statistics\n",
    "    print(f\"\\nSequence Statistics for {gene_name}:\")\n",
    "    print(f\"  Length: {seq_length:,} bp\")\n",
    "    print(f\"  GC content: {gc_content:.2%}\")\n",
    "    print(f\"  CpG motifs: {cpg_count:,}\")\n",
    "    print(f\"  CpG density: {cpg_density:.2f} per 1000 bp\")\n",
    "    print(f\"\\nNucleotide composition:\")\n",
    "    print(f\"  A: {a_count:,} ({a_count/seq_length:.2%})\")\n",
    "    print(f\"  T: {t_count:,} ({t_count/seq_length:.2%})\")\n",
    "    print(f\"  G: {g_count:,} ({g_count/seq_length:.2%})\")\n",
    "    print(f\"  C: {c_count:,} ({c_count/seq_length:.2%})\")\n",
    "else:\n",
    "    print(\"⚠ No sequence available for analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement compute_gc_content function\n",
    "def compute_gc_content(sequence, window=200):\n",
    "    \"\"\"\n",
    "    Compute GC-content using a sliding window across the sequence.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence (str): DNA sequence\n",
    "    - window (int): Window size for sliding window\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.DataFrame: Columns ['start', 'end', 'gc_content']\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Slide a window of size 'window' along the sequence\n",
    "    2. For each window, calculate GC content = (G + C) / window_size\n",
    "    3. Store start position, end position, and GC content\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    seq_len = len(sequence)\n",
    "    \n",
    "    # TODO: Implement sliding window\n",
    "    # Loop through sequence with step size = window\n",
    "    # For each window:\n",
    "    #   - Extract window sequence\n",
    "    #   - Count G and C\n",
    "    #   - Calculate GC content\n",
    "    #   - Append [start, end, gc_content] to results\n",
    "    \n",
    "    # TODO: Create DataFrame\n",
    "    df_gc = None  # Use pd.DataFrame() with columns ['start', 'end', 'gc_content']\n",
    "    \n",
    "    return df_gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute GC content using sliding window\n",
    "if sequence is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Computing GC Content with Sliding Window\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Set window size\n",
    "    window_size = None  # e.g., 200 bp\n",
    "    \n",
    "    # TODO: Compute GC content using compute_gc_content function\n",
    "    df_gc = None\n",
    "    \n",
    "    print(f\"✓ Computed GC content for {len(df_gc)} windows\")\n",
    "    print(f\"\\nFirst 5 windows:\")\n",
    "    # TODO: Display first 5 rows of df_gc\n",
    "else:\n",
    "    print(\"⚠ No sequence available for GC content analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot GC content along the sequence\n",
    "if sequence is not None and 'df_gc' in locals() and df_gc is not None:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Visualizing GC Content Along Gene\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Create plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # TODO: Plot GC content\n",
    "    # Use plt.plot() with df_gc['start'] and df_gc['gc_content']\n",
    "    \n",
    "    # TODO: Add labels and title\n",
    "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"GC content\", fontsize=12, fontweight='bold')\n",
    "    plt.title(f\"GC Content Along {gene_name} Gene (window size: {window_size} bp)\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # TODO: Add horizontal line for overall GC content\n",
    "    # Use plt.axhline() to show the overall GC content as reference\n",
    "    \n",
    "    # TODO: Add grid for better readability\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # TODO: Print summary statistics\n",
    "    print(f\"\\nGC Content Statistics:\")\n",
    "    print(f\"  Mean: {df_gc['gc_content'].mean():.3f}\")\n",
    "    print(f\"  Median: {df_gc['gc_content'].median():.3f}\")\n",
    "    print(f\"  Min: {df_gc['gc_content'].min():.3f}\")\n",
    "    print(f\"  Max: {df_gc['gc_content'].max():.3f}\")\n",
    "    print(f\"  Std Dev: {df_gc['gc_content'].std():.3f}\")\n",
    "else:\n",
    "    print(\"⚠ No GC content data available for plotting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Fetch and Analyze Known Variants\n",
    "\n",
    "**Goal:** Introduce variant data, annotation, and visualization.\n",
    "\n",
    "**Background:** Genetic variants (SNPs, INDELs) are differences in DNA sequence between individuals. Understanding where variants occur and their functional impact is crucial for understanding disease mechanisms and personalized medicine. The Ensembl Variation API provides access to annotated variants from multiple sources.\n",
    "\n",
    "**Task List:**\n",
    "1. Implement the `fetch_variants_for_gene` function:\n",
    "   - Construct the Ensembl Variation API URL\n",
    "   - Make an HTTP GET request\n",
    "   - Parse the JSON response\n",
    "   - Extract variant information (id, start, end, alleles, consequence_type)\n",
    "   - Return a DataFrame\n",
    "2. Fetch variants for your chosen gene\n",
    "3. Convert start/end positions to numeric\n",
    "4. Filter variants by location and impact:\n",
    "   - Promoter region variants (-1000 bp from gene start)\n",
    "   - Coding region variants (based on consequence types)\n",
    "   - High-impact variants (missense, nonsense, etc.)\n",
    "5. Assign impact scores to variants:\n",
    "   - Create a mapping dictionary for consequence types to impact scores\n",
    "   - Assign scores to each variant\n",
    "   - Display impact score distribution\n",
    "6. Create two visualizations:\n",
    "   - Histogram of variant density along the gene\n",
    "   - Scatter plot of variant impact score vs. genomic position (highlight high-impact variants)\n",
    "\n",
    "**Key Concepts:**\n",
    "- Variant annotation and consequence types\n",
    "- Promoter regions and regulatory elements\n",
    "- Coding vs. non-coding variants\n",
    "- Variant impact classification\n",
    "- Data filtering and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement fetch_variants_for_gene function\n",
    "def fetch_variants_for_gene(gene_id):\n",
    "    \"\"\"\n",
    "    Retrieve SNPs/INDELs for a given gene using Ensembl Variation API.\n",
    "    \n",
    "    Parameters:\n",
    "    - gene_id (str): Ensembl gene ID\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Variation table with columns:\n",
    "        ['id', 'start', 'end', 'alleles', 'consequence_type']\n",
    "    \"\"\"\n",
    "    # TODO: Construct the API URL\n",
    "    url = None  # Fill in the URL\n",
    "    \n",
    "    # TODO: Make the API request\n",
    "    response = None  # Use requests.get()\n",
    "    \n",
    "    # TODO: Check if request was successful\n",
    "    \n",
    "    # TODO: Parse JSON response\n",
    "    data = None\n",
    "    \n",
    "    # TODO: Extract variant information\n",
    "    rows = []\n",
    "    # TODO: Loop through data and extract: id, start, end, alleles, consequence_type\n",
    "    \n",
    "    # TODO: Create DataFrame\n",
    "    df = None  # Use pd.DataFrame() with appropriate columns\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Fetch and Analyze Known Variants\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 2: Fetch and Analyze Known Variants\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Check if we have the gene sequence from Exercise 1\n",
    "# If not, re-fetch it or use gene_id if available\n",
    "\n",
    "# TODO: Fetch variants using fetch_variants_for_gene function\n",
    "df_variants = None\n",
    "\n",
    "# TODO: Convert start/end to numeric if needed\n",
    "# Use pd.to_numeric() with errors='coerce'\n",
    "\n",
    "# TODO: Remove rows with invalid positions\n",
    "# Use dropna() on 'start' and 'end' columns\n",
    "\n",
    "# TODO: Display variant statistics\n",
    "# Print total variants, first 5 variants, consequence type counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter variants by location and impact\n",
    "if df_variants is not None and len(df_variants) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Filtering Variants\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Filter 1: Promoter region variants (-1000 bp from gene start)\n",
    "    # Use minimum start position as gene start reference\n",
    "    min_start = None  # Calculate from df_variants\n",
    "    promoter_start = None  # min_start - 1000\n",
    "    promoter_end = None  # min_start\n",
    "    \n",
    "    # TODO: Filter variants in promoter region\n",
    "    df_promoter = None  # Use boolean indexing\n",
    "    \n",
    "    # TODO: Filter 2: Coding region variants\n",
    "    # Define coding-related consequence types\n",
    "    coding_consequences = None  # List of consequence types\n",
    "    \n",
    "    # TODO: Filter variants with coding consequences\n",
    "    df_coding = None\n",
    "    \n",
    "    # TODO: Filter 3: High-impact variants (missense, nonsense)\n",
    "    high_impact_consequences = None  # List of high-impact types\n",
    "    \n",
    "    # TODO: Filter high-impact variants\n",
    "    df_high_impact = None\n",
    "    \n",
    "    # TODO: Print filtering results\n",
    "    print(f\"\\n1. Promoter region variants: {len(df_promoter)}\")\n",
    "    print(f\"2. Coding region variants: {len(df_coding)}\")\n",
    "    print(f\"3. High-impact variants: {len(df_high_impact)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No variants available for filtering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign impact scores to variants\n",
    "if df_variants is not None and len(df_variants) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Assigning Impact Scores\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Define impact score mapping dictionary\n",
    "    # Higher score = more severe impact\n",
    "    # Include: transcript_ablation, splice variants, stop_gained, frameshift,\n",
    "    #          nonsense_variant, missense_variant, synonymous_variant, etc.\n",
    "    impact_scores = {\n",
    "        # TODO: Fill in the mapping\n",
    "        # Example: 'missense_variant': 6,\n",
    "        #          'nonsense_variant': 7,\n",
    "        #          etc.\n",
    "    }\n",
    "    \n",
    "    # TODO: Assign impact scores using map()\n",
    "    df_variants['impact_score'] = None  # Use map() with lambda function\n",
    "    \n",
    "    # TODO: Print impact score distribution\n",
    "    # Use value_counts() and sort_index()\n",
    "    \n",
    "    # TODO: Print mean, max, min impact scores\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No variants available for impact scoring\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot 1: Histogram of variant density along the gene\n",
    "if df_variants is not None and len(df_variants) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Plot 1: Variant Density Histogram\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # TODO: Create histogram\n",
    "    # Use plt.hist() with df_variants['start']\n",
    "    bins = None  # e.g., 50\n",
    "    \n",
    "    # TODO: Add vertical span for promoter region if available\n",
    "    # Use plt.axvspan() for promoter_start to promoter_end\n",
    "    \n",
    "    # TODO: Add labels, title, grid, legend\n",
    "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Variant count\", fontsize=12, fontweight='bold')\n",
    "    plt.title(f\"Variant Density Along {gene_name} Gene\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Histogram created\")\n",
    "else:\n",
    "    print(\"⚠ No variants available for density plot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot 2: Scatter plot of variant impact score vs. genomic position\n",
    "if df_variants is not None and len(df_variants) > 0 and 'impact_score' in df_variants.columns:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Plot 2: Variant Impact Score vs. Genomic Position\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # TODO: Create scatter plot\n",
    "    # Color code by impact score\n",
    "    # Use plt.scatter() with df_variants['start'] and df_variants['impact_score']\n",
    "    # Set c=df_variants['impact_score'] and use a colormap (e.g., 'RdYlGn_r')\n",
    "    \n",
    "    # TODO: Highlight high-impact variants\n",
    "    # If df_high_impact exists and has impact_score column:\n",
    "    #   - Plot them with larger markers, different color, marker='*'\n",
    "    #   - Add label for legend\n",
    "    \n",
    "    # TODO: Add colorbar\n",
    "    # Use plt.colorbar()\n",
    "    \n",
    "    # TODO: Add labels, title, grid, legend\n",
    "    plt.xlabel(\"Genomic position (bp)\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Impact Score\", fontsize=12, fontweight='bold')\n",
    "    plt.title(f\"Variant Impact Score vs. Genomic Position for {gene_name}\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # TODO: Calculate correlation between position and impact score\n",
    "    correlation = None  # Use df_variants['start'].corr(df_variants['impact_score'])\n",
    "    print(f\"\\nCorrelation between position and impact score: {correlation:.3f}\")\n",
    "else:\n",
    "    print(\"⚠ No variants available for impact score plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Retrieve Methylation Profile (ENCODE API)\n",
    "\n",
    "**Goal:** Integrate multi-omics data to identify regulatory variants.\n",
    "\n",
    "**Background:** DNA methylation is an epigenetic modification that can regulate gene expression. Whole-genome bisulfite sequencing (WGBS) provides genome-wide methylation profiles. Integrating variant data with methylation data helps identify regulatory SNPs (rSNPs) that may affect gene expression through epigenetic mechanisms.\n",
    "\n",
    "**Task List:**\n",
    "1. Implement the `fetch_encode_methylation` function:\n",
    "   - Query ENCODE REST API for WGBS files\n",
    "   - Parse JSON response\n",
    "   - Extract file metadata (accession, format, output_type, url)\n",
    "   - Return a DataFrame\n",
    "2. Query ENCODE for WGBS methylation data\n",
    "3. Generate methylation profile for variant positions:\n",
    "   - Find all CpG sites in the sequence\n",
    "   - For each variant position, find nearest CpG site\n",
    "   - Simulate methylation beta values based on:\n",
    "     - Distance to CpG site\n",
    "     - Whether variant is in promoter region\n",
    "   - Create DataFrame with position, methylation, nearest_cpg, distance_to_cpg\n",
    "4. Identify CpG islands:\n",
    "   - Use sliding window approach\n",
    "   - Calculate CpG density for each window\n",
    "   - Identify regions with density > 0.6\n",
    "5. Merge variants with methylation scores:\n",
    "   - Merge on position (start)\n",
    "   - Fill missing values with median\n",
    "6. Identify candidate regulatory SNPs:\n",
    "   - SNPs in highly methylated CpG islands (methylation > 0.7)\n",
    "   - Variants in promoters with methylation > 0.7\n",
    "   - Combine and deduplicate results\n",
    "7. Visualize results:\n",
    "   - Plot methylation profile along gene with regulatory SNPs highlighted\n",
    "   - Plot methylation vs. impact score\n",
    "\n",
    "**Key Concepts:**\n",
    "- Epigenomics and DNA methylation\n",
    "- Multi-omics data integration\n",
    "- Regulatory SNPs (rSNPs)\n",
    "- CpG islands and promoter methylation\n",
    "- ENCODE database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement fetch_encode_methylation function\n",
    "def fetch_encode_methylation(gene_name, limit=200):\n",
    "    \"\"\"\n",
    "    Retrieve WGBS methylation track files from ENCODE.\n",
    "    \n",
    "    Parameters:\n",
    "    - gene_name (str): Used only for reference; ENCODE query is global\n",
    "    - limit (int): Max returned records\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Minimal metadata table for methylation files\n",
    "    \"\"\"\n",
    "    url = \"https://www.encodeproject.org/search/\"\n",
    "    params = {\n",
    "        \"type\": \"File\",\n",
    "        \"assay_title\": \"WGBS\",\n",
    "        \"status\": \"released\",\n",
    "        \"limit\": limit,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    # TODO: Make API request with appropriate headers\n",
    "    response = None  # Use requests.get() with params and headers\n",
    "    \n",
    "    # TODO: Check response and parse JSON\n",
    "    data = None\n",
    "    \n",
    "    # TODO: Extract file information from data['@graph']\n",
    "    rows = []\n",
    "    # TODO: Loop through hits and extract: accession, file_format, output_type, href\n",
    "    \n",
    "    # TODO: Create DataFrame\n",
    "    df = None  # Use pd.DataFrame() with columns ['accession', 'format', 'output_type', 'url']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Retrieve Methylation Profile\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 3: Retrieve Methylation Profile (ENCODE API)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Query ENCODE API for WGBS files\n",
    "df_methylation_files = None  # Use fetch_encode_methylation()\n",
    "\n",
    "# TODO: Display file metadata\n",
    "# Print number of files, first 5 files, file formats, output types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate methylation profile for variant positions\n",
    "if 'sequence' in locals() and sequence is not None and df_variants is not None and len(df_variants) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Generating Methylation Profile\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Find all CpG positions in the sequence\n",
    "    cpg_positions = []\n",
    "    # TODO: Loop through sequence and find \"CG\" dinucleotides\n",
    "    \n",
    "    # TODO: Get variant positions\n",
    "    variant_positions = None  # Extract from df_variants['start']\n",
    "    \n",
    "    # TODO: Create methylation DataFrame\n",
    "    methylation_data = []\n",
    "    # TODO: For each variant position:\n",
    "    #   - Find nearest CpG site\n",
    "    #   - Calculate distance to CpG\n",
    "    #   - Determine if in promoter region\n",
    "    #   - Calculate methylation value (simulate based on distance and promoter status)\n",
    "    #   - Append to methylation_data\n",
    "    \n",
    "    df_methylation = None  # Create DataFrame from methylation_data\n",
    "    \n",
    "    # TODO: Identify CpG islands\n",
    "    # Use sliding window approach\n",
    "    # Calculate CpG density for each window\n",
    "    # Identify regions with density > 0.6\n",
    "    cpg_islands = []\n",
    "    # TODO: Implement CpG island detection\n",
    "    \n",
    "    print(f\"✓ Generated methylation profile\")\n",
    "    print(f\"✓ Identified {len(cpg_islands)} CpG islands\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ Sequence or variants not available\")\n",
    "    df_methylation = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge variants with methylation scores\n",
    "if df_variants is not None and len(df_variants) > 0 and df_methylation is not None and len(df_methylation) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Merging Variants with Methylation Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Merge on position\n",
    "    # Use df_variants.merge() with df_methylation on 'start' and 'position'\n",
    "    df_merged = None\n",
    "    \n",
    "    # TODO: Fill missing methylation values with median\n",
    "    # Use fillna() with median value\n",
    "    \n",
    "    # TODO: Display merged data preview and statistics\n",
    "    print(f\"✓ Merged {len(df_merged)} variants with methylation data\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ Cannot merge: variants or methylation data not available\")\n",
    "    df_merged = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify candidate regulatory SNPs\n",
    "if df_merged is not None and len(df_merged) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Identifying Candidate Regulatory SNPs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Criterion 1: SNPs in highly methylated CpG islands\n",
    "    # Check if variant is in a CpG island AND methylation > 0.7\n",
    "    regulatory_snps_cpg = []\n",
    "    # TODO: Loop through df_merged and check conditions\n",
    "    \n",
    "    df_regulatory_cpg = None  # Create DataFrame from regulatory_snps_cpg\n",
    "    \n",
    "    # TODO: Criterion 2: Variants in promoters with methylation > 0.7\n",
    "    # Filter promoter variants with methylation > 0.7\n",
    "    df_regulatory_promoter = None\n",
    "    \n",
    "    # TODO: Combine all regulatory SNPs and remove duplicates\n",
    "    df_regulatory_all = None  # Use pd.concat() and drop_duplicates()\n",
    "    \n",
    "    # TODO: Display summary statistics\n",
    "    print(f\"  Total candidate regulatory SNPs: {len(df_regulatory_all)}\")\n",
    "    print(f\"  From CpG islands: {len(df_regulatory_cpg)}\")\n",
    "    print(f\"  From promoters: {len(df_regulatory_promoter)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ Cannot identify regulatory SNPs: merged data not available\")\n",
    "    df_regulatory_all = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize methylation profile and regulatory SNPs\n",
    "if df_merged is not None and len(df_merged) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Visualizing Methylation Profile and Regulatory SNPs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # TODO: Plot 1: Methylation along gene with variant positions\n",
    "    ax1 = axes[0]\n",
    "    # TODO: Scatter plot of all variants colored by methylation\n",
    "    # TODO: Highlight regulatory SNPs with larger markers, different color, marker='*'\n",
    "    # TODO: Add promoter region highlight (axvspan)\n",
    "    # TODO: Add CpG island highlights (axvspan for each island)\n",
    "    # TODO: Add colorbar, labels, title, grid, legend\n",
    "    \n",
    "    # TODO: Plot 2: Methylation vs Impact Score\n",
    "    ax2 = axes[1]\n",
    "    # TODO: Scatter plot of impact_score vs methylation\n",
    "    # TODO: Highlight regulatory SNPs\n",
    "    # TODO: Add threshold line at methylation = 0.7\n",
    "    # TODO: Add colorbar, labels, title, grid, legend\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Visualization complete\")\n",
    "else:\n",
    "    print(\"⚠ No data available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Design CRISPR Guide RNAs\n",
    "\n",
    "**Goal:** Connect sequence data with computational CRISPR design.\n",
    "\n",
    "**Background:** CRISPR-Cas9 is a genome editing technology that uses a guide RNA (gRNA) to direct the Cas9 nuclease to specific DNA sequences. The SpCas9 system requires a Protospacer Adjacent Motif (PAM) sequence \"NGG\" (where N is any nucleotide) immediately downstream of the target site. Effective guide design requires considering multiple factors including GC content, avoiding repetitive sequences, and minimizing off-target effects.\n",
    "\n",
    "**Task List:**\n",
    "1. Implement the `find_ngg_sites` function:\n",
    "   - Use regex to find all NGG patterns in the sequence\n",
    "   - For each PAM site, extract the 20-bp guide sequence upstream\n",
    "   - Return DataFrame with guide, pam_start, pam_end\n",
    "2. Identify all PAM sites and extract guide sequences\n",
    "3. Implement the `score_guides` function:\n",
    "   - Calculate GC content score (optimal ~50%)\n",
    "   - Apply poly-T penalty (avoid TTTT runs)\n",
    "   - Calculate position score (prefer guides near TSS)\n",
    "   - Calculate combined weighted score\n",
    "4. Score all guides using multiple criteria\n",
    "5. Perform off-target prediction analysis:\n",
    "   - Calculate sequence complexity\n",
    "   - Estimate off-target count based on complexity and GC content\n",
    "   - Simulate top off-target sites\n",
    "   - Add off-target penalty to final score\n",
    "6. Visualize guide RNA design results:\n",
    "   - Distribution of guide scores\n",
    "   - GC content distribution\n",
    "   - Guide score vs. genomic position\n",
    "   - Off-target count vs. guide score\n",
    "\n",
    "**Key Concepts:**\n",
    "- CRISPR-Cas9 system and PAM sites\n",
    "- Guide RNA design principles\n",
    "- Off-target prediction\n",
    "- Scoring algorithms for guide efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement find_ngg_sites function\n",
    "def find_ngg_sites(sequence):\n",
    "    \"\"\"\n",
    "    Identify PAM sites (NGG) for SpCas9 and extract guide sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence (str): DNA sequence\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: ['guide', 'pam_start', 'pam_end']\n",
    "    \"\"\"\n",
    "    guides = []\n",
    "    # TODO: Use regex to find all NGG patterns\n",
    "    # Use re.finditer() with lookahead pattern: r'(?=(.GG))'\n",
    "    # For each match:\n",
    "    #   - Get PAM start position\n",
    "    #   - If pam_start >= 20, extract 20-bp guide upstream\n",
    "    #   - Append [guide, pam_start, pam_start+3] to guides\n",
    "    \n",
    "    # TODO: Create DataFrame\n",
    "    df = None  # Use pd.DataFrame() with columns ['guide', 'pam_start', 'pam_end']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement score_guides function\n",
    "def score_guides(df_guides, tss_position=0):\n",
    "    \"\"\"\n",
    "    Score guides by GC content, poly-T avoidance, and position relative to TSS.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_guides (DataFrame): Guide sequences with PAM positions\n",
    "    - tss_position (int): Transcription start site position\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with additional scoring columns\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    gc_scores = []\n",
    "    poly_t_penalties = []\n",
    "    position_scores = []\n",
    "    \n",
    "    # TODO: Loop through each guide\n",
    "    for _, row in df_guides.iterrows():\n",
    "        g = row['guide']\n",
    "        pam_pos = row['pam_start']\n",
    "        \n",
    "        # TODO: 1. Calculate GC content score (optimal ~50%)\n",
    "        gc = None  # Calculate GC content\n",
    "        gc_score = None  # Score: 1.0 for 50% GC, decreasing as it deviates\n",
    "        \n",
    "        # TODO: 2. Calculate poly-T penalty\n",
    "        poly_t_penalty = None  # 0.3 for TTTT, 0.1 for TTT, 0.0 otherwise\n",
    "        \n",
    "        # TODO: 3. Calculate position score\n",
    "        distance_from_tss = None  # Calculate distance\n",
    "        position_score = None  # Higher score for guides near TSS\n",
    "        \n",
    "        # TODO: 4. Calculate combined score (weighted)\n",
    "        combined_score = None  # Weight: gc_score*0.4 + position_score*0.3 - poly_t_penalty\n",
    "        \n",
    "        scores.append(combined_score)\n",
    "        gc_scores.append(gc_score)\n",
    "        poly_t_penalties.append(poly_t_penalty)\n",
    "        position_scores.append(position_score)\n",
    "    \n",
    "    # TODO: Add columns to df_guides\n",
    "    df_guides['gc_content'] = None  # Calculate for each guide\n",
    "    df_guides['gc_score'] = gc_scores\n",
    "    df_guides['poly_t_penalty'] = poly_t_penalties\n",
    "    df_guides['position_score'] = position_scores\n",
    "    df_guides['combined_score'] = scores\n",
    "    \n",
    "    return df_guides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Design CRISPR Guide RNAs\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 4: Design CRISPR Guide RNAs\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Check if we have the gene sequence from Exercise 1\n",
    "# If not, re-fetch it\n",
    "\n",
    "# TODO: Find all NGG PAM sites and extract guide sequences\n",
    "df_guides = None  # Use find_ngg_sites()\n",
    "\n",
    "# TODO: Display PAM site distribution\n",
    "# Print number of guides, first 5 guides, position range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Score guides using multiple criteria\n",
    "if df_guides is not None and len(df_guides) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Scoring Guide RNAs\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Set TSS position (use 0 as default)\n",
    "    tss_position = None\n",
    "    \n",
    "    # TODO: Score guides using score_guides function\n",
    "    df_guides = None  # Use score_guides()\n",
    "    \n",
    "    # TODO: Sort by combined score (descending)\n",
    "    df_guides = None  # Use sort_values()\n",
    "    \n",
    "    # TODO: Display scoring statistics\n",
    "    # Print mean, max, min combined score\n",
    "    # Print mean GC content, guides with poly-T runs\n",
    "    \n",
    "    # TODO: Display top 10 guides by combined score\n",
    "    \n",
    "    # TODO: Analyze guide quality distribution\n",
    "    # Categorize: Excellent (≥0.7), Good (0.5-0.7), Fair (0.3-0.5), Poor (<0.3)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No guides available for scoring\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Off-Target Prediction Analysis\n",
    "if df_guides is not None and len(df_guides) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Off-Target Prediction Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Select top guides for off-target analysis\n",
    "    top_guides = None  # Use head(10)\n",
    "    \n",
    "    # TODO: For each guide, simulate off-target predictions\n",
    "    off_target_data = []\n",
    "    # TODO: Loop through top_guides:\n",
    "    #   - Calculate sequence complexity (unique k-mers)\n",
    "    #   - Estimate off-target count based on complexity and GC content\n",
    "    #   - Simulate top 3 off-target sites with mismatches\n",
    "    #   - Append to off_target_data\n",
    "    \n",
    "    df_off_target = None  # Create DataFrame from off_target_data\n",
    "    \n",
    "    # TODO: Add off-target count to main guides dataframe\n",
    "    # Use map() to add 'estimated_off_targets' column\n",
    "    \n",
    "    # TODO: Recalculate final score including off-target penalty\n",
    "    df_guides['off_target_penalty'] = None  # Normalize off-target count\n",
    "    df_guides['final_score'] = None  # combined_score - off_target_penalty\n",
    "    \n",
    "    # TODO: Re-sort by final score\n",
    "    \n",
    "    # TODO: Display top 5 guides by final score\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No guides available for off-target analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize guide RNA design results\n",
    "if df_guides is not None and len(df_guides) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Visualizing Guide RNA Design Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # TODO: Plot 1: Guide scores distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    # TODO: Histogram of combined_score\n",
    "    # TODO: Add vertical line for mean\n",
    "    \n",
    "    # TODO: Plot 2: GC content distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    # TODO: Histogram of gc_content\n",
    "    # TODO: Add vertical line at 0.5 (optimal) and mean\n",
    "    \n",
    "    # TODO: Plot 3: Score vs Position\n",
    "    ax3 = axes[1, 0]\n",
    "    # TODO: Scatter plot of pam_start vs combined_score\n",
    "    # TODO: Color by gc_content\n",
    "    # TODO: Highlight top 10 guides\n",
    "    \n",
    "    # TODO: Plot 4: Off-target vs Score\n",
    "    ax4 = axes[1, 1]\n",
    "    # TODO: Scatter plot of combined_score vs estimated_off_targets\n",
    "    # TODO: Color by final_score\n",
    "    # TODO: Highlight top 10 guides\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Visualization complete\")\n",
    "else:\n",
    "    print(\"⚠ No data available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Synthetic Biology Mini-Model in Python\n",
    "\n",
    "**Goal:** Introduce simple dynamical modeling (ODEs) of gene circuits.\n",
    "\n",
    "**Background:** Synthetic biology uses mathematical models to predict and design biological systems. Ordinary Differential Equations (ODEs) are commonly used to model gene expression dynamics. A toggle switch is a bistable circuit where two genes mutually repress each other, creating two stable states. An activator circuit involves a gene that activates its own expression, creating positive feedback.\n",
    "\n",
    "**Task List:**\n",
    "1. Implement `simulate_gene_ode` function:\n",
    "   - Define ODE: dX/dt = alpha - beta * X\n",
    "   - Use `scipy.integrate.solve_ivp` to integrate\n",
    "   - Return DataFrame with time and expression columns\n",
    "2. Simulate simple gene expression model\n",
    "3. Implement `simulate_toggle_switch` function:\n",
    "   - Define ODEs for mutual repression\n",
    "   - Integrate using solve_ivp\n",
    "   - Return DataFrame with time, X1, X2 columns\n",
    "4. Simulate toggle switch circuit\n",
    "5. Implement `simulate_activator_circuit` function:\n",
    "   - Define ODE with positive feedback\n",
    "   - Include knockdown_factor parameter\n",
    "   - Integrate using solve_ivp\n",
    "6. Simulate activator circuit without knockdown\n",
    "7. Simulate activator circuit with CRISPR knockdown:\n",
    "   - Use top guide from Exercise 4 (if available)\n",
    "   - Simulate with different knockdown strengths\n",
    "   - Compare results\n",
    "8. Create summary visualization comparing all models\n",
    "\n",
    "**Key Concepts:**\n",
    "- Ordinary Differential Equations (ODEs)\n",
    "- Gene circuit modeling\n",
    "- Toggle switches and activator circuits\n",
    "- Numerical integration\n",
    "- CRISPR-mediated gene knockdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement simple gene expression ODE simulation\n",
    "def simulate_gene_ode(alpha=1.0, beta=0.5, t_end=20):\n",
    "    \"\"\"\n",
    "    Simulate simple gene expression ODE: dX/dt = alpha - beta * X\n",
    "    \n",
    "    Parameters:\n",
    "    - alpha (float): Production rate\n",
    "    - beta (float): Degradation rate\n",
    "    - t_end (int): Duration of simulation\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with time series\n",
    "    \"\"\"\n",
    "    def ode(t, X):\n",
    "        # TODO: Return dX/dt = alpha - beta * X\n",
    "        return None\n",
    "    \n",
    "    # TODO: Use solve_ivp to integrate\n",
    "    # t_span=[0, t_end], y0=[0], t_eval=np.linspace(0, t_end, 200)\n",
    "    sol = None\n",
    "    \n",
    "    # TODO: Create DataFrame\n",
    "    df = None  # Use pd.DataFrame() with 'time' and 'expression' columns\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement toggle switch ODE model\n",
    "def simulate_toggle_switch(alpha1=2.0, alpha2=2.0, beta1=1.0, beta2=1.0, \n",
    "                           n=2, K=1.0, t_end=50, initial_conditions=[0.1, 0.1]):\n",
    "    \"\"\"\n",
    "    Simulate a toggle switch circuit:\n",
    "        dX1/dt = alpha1 / (1 + (X2/K)^n) - beta1 * X1\n",
    "        dX2/dt = alpha2 / (1 + (X1/K)^n) - beta2 * X2\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with time series for both genes\n",
    "    \"\"\"\n",
    "    def ode(t, y):\n",
    "        X1, X2 = y\n",
    "        # TODO: Calculate dX1_dt and dX2_dt\n",
    "        dX1_dt = None\n",
    "        dX2_dt = None\n",
    "        return [dX1_dt, dX2_dt]\n",
    "    \n",
    "    # TODO: Use solve_ivp to integrate\n",
    "    sol = None\n",
    "    \n",
    "    # TODO: Create DataFrame with time, X1, X2 columns\n",
    "    df = None\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement activator circuit ODE model\n",
    "def simulate_activator_circuit(alpha=1.0, beta=0.5, n=2, K=0.5, t_end=20, \n",
    "                               initial_condition=0.1, knockdown_factor=1.0):\n",
    "    \"\"\"\n",
    "    Simulate an activator circuit (positive feedback):\n",
    "        dX/dt = alpha * (X^n / (K^n + X^n)) - beta * X * knockdown_factor\n",
    "    \n",
    "    Parameters:\n",
    "    - knockdown_factor: Multiplier for degradation (1.0 = no knockdown, >1.0 = knockdown)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with time series\n",
    "    \"\"\"\n",
    "    def ode(t, X):\n",
    "        # TODO: Calculate production term (positive feedback)\n",
    "        production = None  # alpha * (X^n / (K^n + X^n))\n",
    "        \n",
    "        # TODO: Calculate degradation term (with knockdown)\n",
    "        degradation = None  # beta * X * knockdown_factor\n",
    "        \n",
    "        # TODO: Return dX/dt\n",
    "        return None\n",
    "    \n",
    "    # TODO: Use solve_ivp to integrate\n",
    "    sol = None\n",
    "    \n",
    "    # TODO: Create DataFrame with time and expression columns\n",
    "    df = None\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Synthetic Biology Mini-Model\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 5: Synthetic Biology Mini-Model in Python\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Part 1: Simple gene expression model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 1: Simple Gene Expression Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Simulate simple gene expression\n",
    "df_simple = None  # Use simulate_gene_ode()\n",
    "\n",
    "# TODO: Plot simple model\n",
    "# Plot time vs expression\n",
    "# Add horizontal line for steady state (alpha/beta)\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Part 2: Toggle Switch Circuit\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 2: Toggle Switch Circuit\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Simulate toggle switch\n",
    "df_toggle = None  # Use simulate_toggle_switch()\n",
    "\n",
    "# TODO: Plot toggle switch\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# TODO: Plot 1: Time course\n",
    "ax1 = axes[0]\n",
    "# Plot X1 and X2 vs time\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "# TODO: Plot 2: Phase portrait\n",
    "ax2 = axes[1]\n",
    "# Plot X1 vs X2\n",
    "# Mark start and end points\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Analyze toggle switch behavior\n",
    "# Print final X1 and X2 levels\n",
    "# Determine which state the circuit switched to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Part 3: Activator Circuit (Positive Feedback)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 3: Activator Circuit (Positive Feedback)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Simulate activator circuit without knockdown\n",
    "df_activator_no_kd = None  # Use simulate_activator_circuit() with knockdown_factor=1.0\n",
    "\n",
    "# TODO: Plot activator circuit\n",
    "# Plot time vs expression\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Print analysis\n",
    "# Print final expression level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Part 4: CRISPR Knockdown Effect\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Part 4: CRISPR-Mediated Knockdown Effect\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Check if we have guides from Exercise 4\n",
    "# If available, select top guide and display its information\n",
    "\n",
    "# TODO: Simulate different knockdown strengths\n",
    "# Use knockdown_factors: [1.0, 1.5, 2.0, 3.0, 5.0]\n",
    "knockdown_factors = None\n",
    "knockdown_labels = None\n",
    "\n",
    "knockdown_results = {}\n",
    "# TODO: Loop through knockdown factors and simulate\n",
    "# Store results in knockdown_results dictionary\n",
    "\n",
    "# TODO: Plot comparison\n",
    "# Plot all knockdown scenarios on same plot\n",
    "# Use different colors for each\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Calculate knockdown efficiency\n",
    "# For each knockdown scenario, calculate reduction percentage\n",
    "# Print efficiency analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summary visualization: All models together\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Comparison of All Models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# TODO: Plot 1: Simple model\n",
    "ax1 = axes[0, 0]\n",
    "# Plot simple model\n",
    "# Add steady state line\n",
    "\n",
    "# TODO: Plot 2: Toggle switch\n",
    "ax2 = axes[0, 1]\n",
    "# Plot X1 and X2 vs time\n",
    "\n",
    "# TODO: Plot 3: Activator (no knockdown)\n",
    "ax3 = axes[1, 0]\n",
    "# Plot activator circuit\n",
    "\n",
    "# TODO: Plot 4: Knockdown comparison\n",
    "ax4 = axes[1, 1]\n",
    "# Plot all knockdown scenarios\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Print key takeaways\n",
    "print(f\"\\nKey Takeaways:\")\n",
    "print(f\"  1. Simple model: Linear production and degradation → steady state\")\n",
    "print(f\"  2. Toggle switch: Bistable system with two stable states\")\n",
    "print(f\"  3. Activator circuit: Positive feedback → high expression\")\n",
    "print(f\"  4. CRISPR knockdown: Increases degradation → reduces expression\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
